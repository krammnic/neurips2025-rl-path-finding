{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is it about\n",
    "\n",
    "### Transformer. Notebook trains bunch of transformers with different lengths. Here are my test results on the biggest element.\n",
    "\n",
    "\n",
    "| n_size | path_length | n_ideal | train_time (min) | search_time (sec) |\n",
    "|--------|-------------|-------|------------------|-------------------|\n",
    "| 2      | 1           | 1     | 83               | 40                |\n",
    "| 3      | 1           | 3     | 83               | 60                |\n",
    "| 4      | 6           | 4     | 83               | 110               |\n",
    "| 5      | 10          | 10    | 83               | 150               |\n",
    "| 6      | 15          | 15    | 83               | 150               |\n",
    "| 7      | 21          | 21    | 83               | 320               |\n",
    "| 8      | 45          | 28    | 83               | 400               |\n",
    "| 9      | 107         | 36    | 416              | 516               |\n",
    "| 10     | false       | 45    | 416              | >10000            |\n",
    "| 11     | false       | 55    | 416              | >10000            |\n",
    "| 12     | false       | 66    | 416              | >10000            |\n",
    "| 13     | 332         | 78    | 900              | 1281              |\n",
    "| 14     | false       | 91    | 900              | >10000            |\n",
    "| 15     | 361         | 105   | 900              | 5698              |\n",
    "| 20     | false       | 190   | 2000             | >10000            |\n",
    "\n",
    "### About my model: I use 4 versions of a model (last column shows for which n_sizes I used it): \n",
    "| Version | proj_dim | n_layers | num_epochs | data_per_epoch | ns      |\n",
    "|---------|----------|----------|------------|----------------|---------|\n",
    "| 1       | 128      | 16       | 50         | 100_000        | 2-9     |\n",
    "| 2       | 512      | 32       | 100        | 100_000        | 9-13    |\n",
    "| 3       | 1024     | 16       | 100        | 200_000        | 13-19   |\n",
    "| 4       | 1024     | 32       | 100        | 200_000        | 19 & 20 |\n",
    "\n",
    "### Constants: beam_width: 2**11, max_length: 1500, batch_size: 32, n_heads: 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/iKolt/cayleypy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from cayleypy.cayleypy import *\n",
    "\n",
    "from tqdm import notebook as tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CFG = { 'dimension'               : 15, # N\n",
    "        'generators_family'       : 'S_N',\n",
    "        ##################################################################\n",
    "        \n",
    "    \n",
    "        #'group_and_generators_id' : 'cube_3/3/3_12gensQTM',#'cube_4/4/4',\n",
    "        #'flag_add_inverses'       :  True                 , \n",
    "        'range_of_cubies'         :  20                  ,\n",
    "\n",
    "       \n",
    "        ### adavanced beam search params\n",
    "        'beam_width'                      : 2**10 , \n",
    "        'n_steps_limit'                   : 1500  ,\n",
    "        'n_step_size'                     : 1     , \n",
    "        'n_beam_candidate_states'         : 'Auto',\n",
    "        'radius_destination_neigbourhood' : 0     ,\n",
    "        'radius_beam_neigbourhood'        : 0     , # not used actually\n",
    "        'bi_bfs_chunk_size_states'        : 2**16 , # not used actually\n",
    "        'mode_bibfs_checks'               : (10,5), # not used actually\n",
    "        'temperature'                     : 0     ,\n",
    "        'temperature_decay'               : 1     ,\n",
    "        'alpha_past_states_attenuation'   : 0     ,\n",
    "        'n_steps_to_ban_backtracking'     : 0     ,\n",
    "        'flag_empty_backtracking_list'    : False ,\n",
    "        'n_attempts_limit'                : 1     ,\n",
    "        'do_check_stagnation'             : False , \n",
    "        'stagnation_steps'                : 12    ,\n",
    "        'stagnation_thres'                : 0.005 ,\n",
    "        'n_random_start_steps'            : 0     ,\n",
    "        'diversity_func'                  : hamming_dist,\n",
    "        'diversity_weight'                : 0     ,\n",
    "        'sub_ray_split'                   : False ,\n",
    "        #'random_seed'                     : -23057572\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "list_groups_generators = ['cube_2/2/2_6gensQTM', 'cube_3/3/3_12gensQTM', 'cube_2/2/2', 'cube_3/3/3', 'cube_4/4/4','cube_5/5/5',\n",
    "'cube_6/6/6', 'cube_7/7/7', 'cube_8/8/8', 'cube_9/9/9', 'cube_10/10/10', 'cube_19/19/19', 'cube_33/33/33',\n",
    "'wreath_100/100', 'wreath_33/33', 'wreath_21/21', 'wreath_12/12', 'wreath_7/7', 'wreath_6/6', 'globe_1/8',\n",
    "'globe_1/16' ,'globe_2/6' ] \n",
    "\n",
    "def get_dict_generators( group_gens_id, flag_add_inverses = True  ):\n",
    "\n",
    "    if group_gens_id == 'cube_2/2/2_6gensQTM':\n",
    "        dict_allowed_moves  = {\\\n",
    "        'f0':[ 0,  1, 19, 17,  6,  4,  7,  5,  2,  9,  3, 11, 12, 13, 14, 15, 16, 20, 18, 21, 10,  8, 22, 23],\n",
    "        '-f0':[ 0,  1,  8, 10,  5,  7,  4,  6, 21,  9, 20, 11, 12, 13, 14, 15, 16,  3, 18,  2, 17, 19, 22, 23],\n",
    "        'r1':[ 0,  5,  2,  7,  4, 21,  6, 23, 10,  8, 11,  9,  3, 13,  1, 15, 16, 17, 18, 19, 20, 14, 22, 12],\n",
    "        '-r1':[ 0, 14,  2, 12,  4,  1,  6,  3,  9, 11,  8, 10, 23, 13, 21, 15, 16, 17, 18, 19, 20,  5, 22,  7],\n",
    "        'd0':[ 0,  1,  2,  3,  4,  5, 18, 19,  8,  9,  6,  7, 12, 13, 10, 11, 16, 17, 14, 15, 22, 20, 23, 21],\n",
    "        '-d0':[ 0,  1,  2,  3,  4,  5, 10, 11,  8,  9, 14, 15, 12, 13, 18, 19, 16, 17,  6,  7, 21, 23, 20, 22]}\n",
    "    elif group_gens_id ==  'cube_3/3/3_12gensQTM':\n",
    "        dict_allowed_moves  = {\\\n",
    "        'U': [6, 3, 0, 7, 4, 1, 8, 5, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 47, 21, 22, 50, 24, 25, 53, 27, 28, 38, 30, 31, 41, 33, 34, 44, 36, 37, 20, 39, 40, 23, 42, 43, 26, 45, 46, 29, 48, 49, 32, 51, 52, 35], \n",
    "        'D': [0, 1, 2, 3, 4, 5, 6, 7, 8, 15, 12, 9, 16, 13, 10, 17, 14, 11, 36, 19, 20, 39, 22, 23, 42, 25, 26, 45, 28, 29, 48, 31, 32, 51, 34, 35, 27, 37, 38, 30, 40, 41, 33, 43, 44, 18, 46, 47, 21, 49, 50, 24, 52, 53],\n",
    "        'L': [44, 43, 42, 3, 4, 5, 6, 7, 8, 45, 46, 47, 12, 13, 14, 15, 16, 17, 24, 21, 18, 25, 22, 19, 26, 23, 20, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 11, 10, 9, 0, 1, 2, 48, 49, 50, 51, 52, 53],\n",
    "        'R': [0, 1, 2, 3, 4, 5, 51, 52, 53, 9, 10, 11, 12, 13, 14, 38, 37, 36, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 30, 27, 34, 31, 28, 35, 32, 29, 8, 7, 6, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 15, 16, 17],\n",
    "        'B': [0, 1, 35, 3, 4, 34, 6, 7, 33, 20, 10, 11, 19, 13, 14, 18, 16, 17, 2, 5, 8, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 9, 12, 15, 42, 39, 36, 43, 40, 37, 44, 41, 38, 45, 46, 47, 48, 49, 50, 51, 52, 53],\n",
    "        'F' : [24, 1, 2, 25, 4, 5, 26, 7, 8, 9, 10, 27, 12, 13, 28, 15, 16, 29, 18, 19, 20, 21, 22, 23, 17, 14, 11, 6, 3, 0, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 51, 48, 45, 52, 49, 46, 53, 50, 47] ,\n",
    "        \"U'\" : [2, 5, 8, 1, 4, 7, 0, 3, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 38, 21, 22, 41, 24, 25, 44, 27, 28, 47, 30, 31, 50, 33, 34, 53, 36, 37, 29, 39, 40, 32, 42, 43, 35, 45, 46, 20, 48, 49, 23, 51, 52, 26] ,\n",
    "        \"D'\" : [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 17, 10, 13, 16, 9, 12, 15, 45, 19, 20, 48, 22, 23, 51, 25, 26, 36, 28, 29, 39, 31, 32, 42, 34, 35, 18, 37, 38, 21, 40, 41, 24, 43, 44, 27, 46, 47, 30, 49, 50, 33, 52, 53] ,\n",
    "        \"L'\" : [45, 46, 47, 3, 4, 5, 6, 7, 8, 44, 43, 42, 12, 13, 14, 15, 16, 17, 20, 23, 26, 19, 22, 25, 18, 21, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 2, 1, 0, 9, 10, 11, 48, 49, 50, 51, 52, 53] ,\n",
    "        \"R'\" : [0, 1, 2, 3, 4, 5, 38, 37, 36, 9, 10, 11, 12, 13, 14, 51, 52, 53, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 32, 35, 28, 31, 34, 27, 30, 33, 17, 16, 15, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 6, 7, 8] ,\n",
    "        \"B'\" : [0, 1, 18, 3, 4, 19, 6, 7, 20, 33, 10, 11, 34, 13, 14, 35, 16, 17, 15, 12, 9, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 8, 5, 2, 38, 41, 44, 37, 40, 43, 36, 39, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53] ,\n",
    "        \"F'\" : [29, 1, 2, 28, 4, 5, 27, 7, 8, 9, 10, 26, 12, 13, 25, 15, 16, 24, 18, 19, 20, 21, 22, 23, 0, 3, 6, 11, 14, 17, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 50, 53, 46, 49, 52, 45, 48, 51],\n",
    "        }                               \n",
    "    else:\n",
    "        fn = '/growth-in-finite-groups/puzzle_info.csv'\n",
    "        di = pd.read_csv(fn)\n",
    "        m = di['puzzle_type'] == group_gens_id\n",
    "        allowed_moves = di['allowed_moves'][m].iat[0]\n",
    "        allowed_moves = str( allowed_moves ).replace(\"'\", '\"')\n",
    "        import json\n",
    "        dict_allowed_moves = json.loads(allowed_moves)\n",
    "        #print(str(dict_allowed_moves)[:500] )\n",
    "        \n",
    "#         vec_len = len( dict_allowed_moves[list(dict_allowed_moves.keys())[0]])\n",
    "#         array_allowed_moves = np.zeros(  (len(dict_allowed_moves),  vec_len), dtype = int )\n",
    "#         for i in range(len(dict_allowed_moves)):\n",
    "#             array_allowed_moves[i,:] = dict_allowed_moves[list(dict_allowed_moves.keys())[i]]\n",
    "#         array_allowed_moves    \n",
    "\n",
    "    if not flag_add_inverses:\n",
    "        return dict_allowed_moves\n",
    "        \n",
    "        \n",
    "    def inverse_permutation(perm):\n",
    "        # Create an empty list to hold the inverse permutation\n",
    "        inverse = [0] * len(perm)\n",
    "        # Iterate over the original permutation\n",
    "        for i, p in enumerate(perm):\n",
    "            # Place the index at the correct position in the inverse permutation\n",
    "            inverse[p] = i\n",
    "        return inverse        \n",
    "    \n",
    "    dict_allowed_moves_with_inverses = dict_allowed_moves.copy()\n",
    "    for k1 in dict_allowed_moves:\n",
    "        perm1 = dict_allowed_moves[k1]\n",
    "        flag_inverse_found = False\n",
    "        for k2 in dict_allowed_moves:\n",
    "            perm2 = dict_allowed_moves[k2]\n",
    "            if perm1 == inverse_permutation(perm2):\n",
    "                flag_inverse_found = True\n",
    "                break\n",
    "        if not flag_inverse_found:\n",
    "            dict_allowed_moves_with_inverses['-'+k1] = inverse_permutation(perm1)\n",
    "            \n",
    "    return dict_allowed_moves_with_inverses\n",
    "\n",
    "\n",
    "# group_gens_id = 'cube_2/2/2_6gensQTM' \n",
    "# group_gens_id = 'cube_2/2/2'#_6gensQTM' \n",
    "# group_gens_id = CFG['group_and_generators_id']#'cube_3/3/3_12gensQTM'\n",
    "# dict_generators = get_dict_generators( group_gens_id, flag_add_inverses = True  )\n",
    "# list_generators = list(dict_generators.values())\n",
    "# print('Geneators number:', len( dict_generators.keys()) , 'state_size:', len( list_generators[0] ))\n",
    "# print('Geneators names:', dict_generators.keys() )\n",
    "# print( str(dict_generators)[:2000] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_S_N(N):\n",
    "    return [\n",
    "        [1,0,]+[q+2 for q in range(N-2)]       ,\n",
    "               [q+1 for q in range(N-1)] + [0,],\n",
    "        [N-1,]+[q+0 for q in range(N-1)]       ,\n",
    "    ]\n",
    "\n",
    "def make_permutohedron(N):\n",
    "    return [\n",
    "        list(range(0,i)) + [i+1,i,] + list(range(i+2,N)) for i in range(N-1)\n",
    "    ]# + [[N-1,]+list(range(1,N-1))+[0,]]\n",
    "\n",
    "def make_all_pair_perms(N):\n",
    "    res = []\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            candidate = list(range(N))\n",
    "            if i!=j:\n",
    "                candidate[i] = j\n",
    "                candidate[j] = i\n",
    "                res.append(tuple(candidate))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def make_pancake(N):\n",
    "    return [\n",
    "        list(range(i,-1,-1)) + list(range(i+1, N)) for i in range(1,N)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "families = {'S_N':make_S_N,\n",
    "            'PHD':make_permutohedron,\n",
    "            'PRS':make_all_pair_perms,\n",
    "            'PNC':make_pancake,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "list_generators = families[CFG['generators_family']](CFG['dimension'])\n",
    "\n",
    "cayley_group_ex = CayleyGraph( list_generators, to_power=1 )#, random_seed = 4073572258)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cayley_group_ex.manhatten_moves_matrix_count(steps = 1000, to_power=1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "metric = lambda x: hamming_dist(x, cayley_group_ex.state_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "states_to_solve = list(reversed([cayley_group_ex.scramble_state(100+q%2) for q in range(CFG['range_of_cubies'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cayley_group_ex._vls[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def solve(sts, model):\n",
    "    flag_found_destination, i_step, dict_additional_data  =\\\n",
    "            cayley_group_ex.beam_search_permutations_torch(\n",
    "                state_start                     = sts                                   ,\n",
    "                models_or_heuristics            = model, #cayley_group_ex.group_data_1,#metric                                ,\n",
    "                \n",
    "                beam_width                      = CFG[\"beam_width\"                     ],\n",
    "                n_steps_limit                   = CFG[\"n_steps_limit\"                  ],\n",
    "                n_step_size                     = CFG[\"n_step_size\"                    ],\n",
    "                n_beam_candidate_states         = CFG[\"n_beam_candidate_states\"        ],\n",
    "                radius_destination_neigbourhood = CFG[\"radius_destination_neigbourhood\"],\n",
    "                radius_beam_neigbourhood        = CFG[\"radius_beam_neigbourhood\"       ],\n",
    "                bi_bfs_chunk_size_states        = CFG[\"bi_bfs_chunk_size_states\"       ],\n",
    "                mode_bibfs_checks               = CFG[\"mode_bibfs_checks\"              ],\n",
    "                temperature                     = CFG[\"temperature\"                    ],\n",
    "                alpha_past_states_attenuation   = CFG[\"alpha_past_states_attenuation\"  ],\n",
    "                n_steps_to_ban_backtracking     = CFG[\"n_steps_to_ban_backtracking\"    ],\n",
    "                flag_empty_backtracking_list    = CFG[\"flag_empty_backtracking_list\"   ],\n",
    "                n_attempts_limit                = CFG[\"n_attempts_limit\"               ],\n",
    "                do_check_stagnation             = CFG[\"do_check_stagnation\"            ],\n",
    "                stagnation_steps                = CFG[\"stagnation_steps\"               ],\n",
    "                stagnation_thres                = CFG[\"stagnation_thres\"               ],\n",
    "                n_random_start_steps            = CFG[\"n_random_start_steps\"           ],\n",
    "\n",
    "                diversity_func                  = CFG['diversity_func'                 ],\n",
    "                diversity_weight                = CFG['diversity_weight'               ],\n",
    "                sub_ray_split                   = CFG['sub_ray_split'                  ],\n",
    "\n",
    "                verbose                         = 1,\n",
    "                  \n",
    "              )\n",
    "    \n",
    "    return flag_found_destination, i_step, dict_additional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def gen_n(n):\n",
    "    p = np.arange(n)\n",
    "\n",
    "    p[0], p[1] = p[1], p[0]\n",
    "    i = 2\n",
    "    while i < n-i+1:\n",
    "        print(i, n-i+1)\n",
    "        p[i], p[n-i+1] = p[n-i+1], p[i]\n",
    "        i += 1\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PatchEncoder(nn.Module):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        \n",
    "        self.position_embedding = nn.Embedding(num_patches, projection_dim)\n",
    "        self.register_buffer('positions', torch.arange(num_patches).unsqueeze(0))\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, patch):\n",
    "        \n",
    "        encoded = patch + self.position_embedding(self.positions)\n",
    "        return encoded\n",
    "     \n",
    "    def get_config(self):\n",
    "        config = {\"num_patches\": self.num_patches}\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_units, dropout_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        \n",
    "        for units in hidden_units:\n",
    "            layers.append(nn.Linear(in_dim, units))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            in_dim = units\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, projection_dim, num_heads, transformer_units, dropout_rate=0.01):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(projection_dim, eps=1e-6)\n",
    "        self.attention = nn.MultiheadAttention(projection_dim, num_heads, dropout=dropout_rate)\n",
    "        self.norm2 = nn.LayerNorm(projection_dim, eps=1e-6)\n",
    "        self.mlp = MLP(projection_dim, transformer_units, dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.norm1(x)\n",
    "        attn_output, _ = self.attention(x1, x1, x1)\n",
    "        x2 = x + attn_output\n",
    "        x3 = self.norm2(x2)\n",
    "        x3 = self.mlp(x3)\n",
    "        return x2 + x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AdvancedTransformerModel(nn.Module):\n",
    "    def __init__(self, color_size, projection_dim, num_heads, num_layers, dropout_rate=0.1):\n",
    "        super(AdvancedTransformerModel, self).__init__()\n",
    "        \n",
    "        self.projection_dim = projection_dim\n",
    "        self.embedding = nn.Linear(color_size, projection_dim)      \n",
    "        self.positional_encoder = PatchEncoder(color_size, projection_dim)\n",
    "        self.transformer_units = [projection_dim * 2, projection_dim]\n",
    "        self.transformer_blocks = nn.ModuleList([TransformerBlock(projection_dim, num_heads, self.transformer_units) for _ in range(num_layers)])                \n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        self.dense_v1 = nn.Linear(projection_dim, projection_dim)\n",
    "        self.dense_v2 = nn.Linear(projection_dim, projection_dim)\n",
    "        self.dense_v3 = nn.Linear(projection_dim, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if x.dtype == torch.uint8:\n",
    "            x = x.to(torch.float32)\n",
    "\n",
    "        x = self.embedding(x).unsqueeze(1)\n",
    "        x = self.positional_encoder(x)\n",
    "        \n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "                \n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        x = self.global_avg_pool(x).squeeze(-1)\n",
    "        \n",
    "        v = self.dense_v1(x)\n",
    "        v = self.dropout(v)\n",
    "        v = self.dense_v2(v)\n",
    "        v = self.dropout(v)\n",
    "        v = self.dense_v3(v)\n",
    "        \n",
    "        return v.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def trainer(model, dataset_size, n_epochs, once=32, verbose=True, n=0):\n",
    "    model.train()\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "    losses = []\n",
    "   \n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        mse_sum = 0.0\n",
    "\n",
    "        # if epoch % 50 == 0:\n",
    "        #     checkpoint = {\n",
    "        #         'epoch': epoch,               \n",
    "        #         'model_state_dict': model.state_dict(),\n",
    "        #         'optimizer_state_dict': optimizer.state_dict(), \n",
    "        #         'loss': criterion,                       \n",
    "        #     }\n",
    "            \n",
    "        #     torch.save(checkpoint, 'checkpoint.pth')\n",
    "\n",
    "        X, y = cayley_group_ex.random_walks(CFG['n_steps_limit'], dataset_size//200)\n",
    "\n",
    "        for batch in range(dataset_size//once):\n",
    "            \n",
    "            X_, y_ = X[batch*once:(batch+1)*once].float().to(device), y[batch*once:(batch+1)*once].float().to(device)\n",
    "\n",
    "            preds = model(X_)\n",
    "            loss = criterion(preds, y_)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            mse_sum += ((preds - y_) ** 2).sum().item()\n",
    "\n",
    "        if verbose == True:\n",
    "            train_loss = running_loss / dataset_size\n",
    "            train_mse = mse_sum / dataset_size\n",
    "            train_rmse = train_mse ** 0.5\n",
    "\n",
    "            print(f'Epoch {epoch}/{n_epochs}: loss: {train_loss};')\n",
    "            print(f'MSE: {train_mse} RMSE: {train_rmse}')\n",
    "            print()\n",
    "\n",
    "            losses.append(train_loss)\n",
    "\n",
    "    if verbose == True:\n",
    "\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,               \n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(), \n",
    "            'loss': criterion,                       \n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, f'checkpoint_{n}.pth')\n",
    "    \n",
    "        del X\n",
    "        del y\n",
    "        del optimizer\n",
    "        del criterion\n",
    "        del loss\n",
    "        del train_loss\n",
    "        del train_mse\n",
    "        del train_rmse\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "                \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ns = [13,14,15,16,17,18,19]\n",
    "\n",
    "ns1 = [2,3,4,5,6,7,8]\n",
    "ns2 = [9,10,11,12]\n",
    "ns3 = [13,14,15,16,17,18]\n",
    "ns4 = [19,20]\n",
    "\n",
    "# Groups of ns: 1-6, 7-12, 13-18, 19-20\n",
    "params = [[128, 16, 50, 100_000], [512, 32, 100, 100_000], [1024, 16, 100, 200_000], [1024, 32, 100, 200_000]]\n",
    "\n",
    "for n in ns:\n",
    "    list_generators = families[CFG['generators_family']](n)\n",
    "\n",
    "    cayley_group_ex = CayleyGraph( list_generators, to_power=1 )\n",
    "    metric = lambda x: hamming_dist(x, cayley_group_ex.state_destination)\n",
    "    \n",
    "    once = 32\n",
    "\n",
    "    if n in ns1:\n",
    "        param = params[0]\n",
    "        once *= 2\n",
    "    elif n in ns2:\n",
    "        param = params[1]\n",
    "    elif n in ns3:\n",
    "        param = params[2] \n",
    "        once *= 2\n",
    "    elif n in ns4:\n",
    "        param = params[3]\n",
    "\n",
    "    model = AdvancedTransformerModel(color_size = n, projection_dim = param[0], num_heads = 4, num_layers = param[1], dropout_rate=0.00).to(device)\n",
    "    model, losses = trainer(model, param[3], param[2], once=once, verbose=True, n=n)\n",
    "\n",
    "    flag_found_destination, i_step, dict_additional_data = solve(gen_n(n), model)\n",
    "\n",
    "    with open(f'result_{n}.txt', 'w') as f:\n",
    "        f.write(str(flag_found_destination))\n",
    "        f.write('\\n')\n",
    "        f.write(str(i_step))\n",
    "        f.write('\\n')\n",
    "        f.write(str(dict_additional_data))\n",
    "    \n",
    "    fig, ax = plt.subplots( nrows=1, ncols=1 )  \n",
    "    ax.plot(losses)\n",
    "    fig.savefig(f'result_{n}.png') \n",
    "    plt.close(fig) \n",
    "\n",
    "    del flag_found_destination\n",
    "    del i_step\n",
    "    del dict_additional_data\n",
    "    del model\n",
    "    del losses\n",
    "    \n",
    "    import gc\n",
    "    gc.collect()\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11024468,
     "sourceId": 92501,
     "sourceType": "competition"
    },
    {
     "datasetId": 4441442,
     "sourceId": 9604131,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6666681,
     "sourceId": 10749328,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
