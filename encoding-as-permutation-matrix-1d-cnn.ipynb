{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e958b617",
   "metadata": {
    "papermill": {
     "duration": 0.006201,
     "end_time": "2025-02-19T02:33:13.533689",
     "exception": false,
     "start_time": "2025-02-19T02:33:13.527488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What is about ?\n",
    "\n",
    "Preliminary draft\n",
    "\n",
    "Baseline to decompose element into product of generators by ML methods. Permutation groups. \n",
    "\n",
    "    - Generate train set by random walks , i.e. pairs (g, k) \n",
    "    - Train model to preduct k from g\n",
    "    - Use it as heuristics in any algorithm which finds global minima of distnace, e.g. Metpropolis\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a79600",
   "metadata": {
    "papermill": {
     "duration": 0.005359,
     "end_time": "2025-02-19T02:33:13.544803",
     "exception": false,
     "start_time": "2025-02-19T02:33:13.539444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Example to use one-hot  encoding to convert permutations from vector format to permutation-matrix format\n",
    "\n",
    "https://en.wikipedia.org/wiki/Permutation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7124f",
   "metadata": {
    "papermill": {
     "duration": 0.005353,
     "end_time": "2025-02-19T02:33:13.555628",
     "exception": false,
     "start_time": "2025-02-19T02:33:13.550275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ed54e",
   "metadata": {
    "papermill": {
     "duration": 0.005342,
     "end_time": "2025-02-19T02:33:13.566450",
     "exception": false,
     "start_time": "2025-02-19T02:33:13.561108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Examples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa59c52",
   "metadata": {
    "papermill": {
     "duration": 0.00559,
     "end_time": "2025-02-19T02:33:13.577471",
     "exception": false,
     "start_time": "2025-02-19T02:33:13.571881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preliminaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2577fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:13.590243Z",
     "iopub.status.busy": "2025-02-19T02:33:13.589724Z",
     "iopub.status.idle": "2025-02-19T02:33:15.536732Z",
     "shell.execute_reply": "2025-02-19T02:33:15.535839Z"
    },
    "papermill": {
     "duration": 1.956204,
     "end_time": "2025-02-19T02:33:15.539317",
     "exception": false,
     "start_time": "2025-02-19T02:33:13.583113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "t0start = time.time() \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "# i = 0\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "# #     if dirname == '/kaggle/input/growth-in-finite-groups/UT4_growth':\n",
    "#     for filename in filenames:\n",
    "#         i+=1\n",
    "#         if i<= 1:\n",
    "#             print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5da4c421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:15.560911Z",
     "iopub.status.busy": "2025-02-19T02:33:15.560164Z",
     "iopub.status.idle": "2025-02-19T02:33:16.604871Z",
     "shell.execute_reply": "2025-02-19T02:33:16.604117Z"
    },
    "papermill": {
     "duration": 1.056908,
     "end_time": "2025-02-19T02:33:16.606613",
     "exception": false,
     "start_time": "2025-02-19T02:33:15.549705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Heis 3 gens data'\r\n",
      " HeisenbergComputations.sage\r\n",
      "'Rationality of growths of groups Ho.pdf'\r\n",
      " UT4_growth\r\n",
      " UT4_states_and_distances\r\n",
      " UT5_growth\r\n",
      " UT5_states_and_distances\r\n",
      " UT6_growth\r\n",
      " UT6_states_and_distances\r\n",
      " UT7_growth\r\n",
      " UT8_growth\r\n",
      " cubes444_Santa_states_and_n_best_moves.csv\r\n",
      " empty.txt\r\n",
      " puzzle_info.csv\r\n",
      " puzzles_best_scores_numeric_states_etc.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/growth-in-finite-groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ed02d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:16.620239Z",
     "iopub.status.busy": "2025-02-19T02:33:16.619921Z",
     "iopub.status.idle": "2025-02-19T02:33:20.524323Z",
     "shell.execute_reply": "2025-02-19T02:33:20.523373Z"
    },
    "papermill": {
     "duration": 3.913197,
     "end_time": "2025-02-19T02:33:20.526035",
     "exception": false,
     "start_time": "2025-02-19T02:33:16.612838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import math\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    dtype = torch.float\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    dtype = torch.float#int16  \n",
    "    dtype = torch.int16  \n",
    "    \n",
    "print(dtype)    \n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf6234",
   "metadata": {
    "papermill": {
     "duration": 0.005508,
     "end_time": "2025-02-19T02:33:20.537694",
     "exception": false,
     "start_time": "2025-02-19T02:33:20.532186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preliminaries Groups data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf7c72",
   "metadata": {
    "papermill": {
     "duration": 0.005619,
     "end_time": "2025-02-19T02:33:20.548984",
     "exception": false,
     "start_time": "2025-02-19T02:33:20.543365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load moves data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b0a891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:20.561475Z",
     "iopub.status.busy": "2025-02-19T02:33:20.561075Z",
     "iopub.status.idle": "2025-02-19T02:33:20.564826Z",
     "shell.execute_reply": "2025-02-19T02:33:20.564123Z"
    },
    "papermill": {
     "duration": 0.011798,
     "end_time": "2025-02-19T02:33:20.566403",
     "exception": false,
     "start_time": "2025-02-19T02:33:20.554605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "# # fn = '/kaggle/input/santa-2023/puzzle_info.csv'\n",
    "# fn = '/kaggle/input/growth-in-finite-groups/puzzle_info.csv'\n",
    "# di = pd.read_csv(fn)\n",
    "# di['n_generators'] = di['allowed_moves'].apply(lambda x: len(x.split(':'))-1)\n",
    "# di['vector_len'] = di['allowed_moves'].apply(lambda x: len(x.split(']')[0].split('[')[1].split(',')))\n",
    "# di['puzzle_type_brief'] = di['puzzle_type'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "# display(di)\n",
    "# di.to_csv('moves.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167abc69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:20.578749Z",
     "iopub.status.busy": "2025-02-19T02:33:20.578505Z",
     "iopub.status.idle": "2025-02-19T02:33:20.583990Z",
     "shell.execute_reply": "2025-02-19T02:33:20.583171Z"
    },
    "papermill": {
     "duration": 0.013565,
     "end_time": "2025-02-19T02:33:20.585657",
     "exception": false,
     "start_time": "2025-02-19T02:33:20.572092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081fc908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:20.598466Z",
     "iopub.status.busy": "2025-02-19T02:33:20.598221Z",
     "iopub.status.idle": "2025-02-19T02:33:20.605688Z",
     "shell.execute_reply": "2025-02-19T02:33:20.605058Z"
    },
    "papermill": {
     "duration": 0.015669,
     "end_time": "2025-02-19T02:33:20.607229",
     "exception": false,
     "start_time": "2025-02-19T02:33:20.591560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_walks(n_random_walk_length,  n_random_walks_to_generate):\n",
    "      '''\n",
    "      Output:\n",
    "      returns X,y: X - array of states, y - number of steps rw achieves it\n",
    "\n",
    "      Input:\n",
    "      generators - generators (moves) to make random walks  (permutations),\n",
    "          can be list of vectors or array with vstacked vectors\n",
    "      n_random_walk_length - number of visited nodes, i.e. number of steps + 1\n",
    "      n_random_walks_to_generate - how many random walks will run in parrallel\n",
    "      rw_start - initial states for random walks - by default we will use 0,1,2,3 ...\n",
    "          Can be vector or array\n",
    "          If it is vector it will be broadcasted n_random_walks_to_generate times,\n",
    "          If it is array n_random_walks_to_generate - input n_random_walks_to_generate will be ignored\n",
    "              and will be assigned: n_random_walks_to_generate = rw_start.shape[0]\n",
    "\n",
    "      '''\n",
    "      state_size        = len(list_generators[0])\n",
    "      n_generators      = len(list_generators  )\n",
    "      dtype_generators = torch.int64\n",
    "      tensor_generators = torch.tensor(   list_generators       , device = device, dtype = dtype_generators, )\n",
    "      state_destination = torch.arange( state_size, device=device, dtype = dtype).reshape(-1,state_size)\n",
    "      array_of_states = state_destination.to(device).view( 1, state_size  ).expand( n_random_walks_to_generate, state_size )\n",
    "\n",
    "      # Output: X,y - states, y - how many steps we achieve them\n",
    "      # Allocate memory:\n",
    "      X = torch.zeros( n_random_walks_to_generate*n_random_walk_length , state_size, device=device, dtype = dtype )\n",
    "\n",
    "      # First portion of data  - just our state_rw_start state  multiplexed many times\n",
    "      X[:n_random_walks_to_generate,:] = array_of_states\n",
    "      y        = torch.tensor(range(n_random_walks_to_generate*n_random_walk_length), device=device)//n_random_walks_to_generate\n",
    "      IX_moves = torch.randint(0, n_generators, (n_random_walks_to_generate*n_random_walk_length-n_random_walks_to_generate,), dtype = torch.int32, device=device)\n",
    "\n",
    "      # Technical to make array[ IX_array] we need  actually to write array[ range(N), IX_array  ]\n",
    "\n",
    "      # Main loop\n",
    "\n",
    "      argnr = (torch.arange(n_random_walks_to_generate, dtype=torch.long, device=device)*torch.ones((n_random_walks_to_generate,tensor_generators.shape[1]), dtype=torch.long, device=device).T).T\n",
    "\n",
    "      for i_step in range(1,n_random_walk_length):\n",
    "          a,b,c = (i_step-1)*n_random_walks_to_generate, (i_step-0)*n_random_walks_to_generate, (i_step+1)*n_random_walks_to_generate\n",
    "          #X[ b:c, : ] = X[ a:b, : ][argnr, self.tensor_generators[IX_moves[ a:b ],:]]\n",
    "          X[ b:c, : ] = torch.gather( X[ a:b, : ], 1, tensor_generators[IX_moves[ a:b ],:] )\n",
    "\n",
    "      return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437c234a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:20.619964Z",
     "iopub.status.busy": "2025-02-19T02:33:20.619751Z",
     "iopub.status.idle": "2025-02-19T02:33:20.639855Z",
     "shell.execute_reply": "2025-02-19T02:33:20.639221Z"
    },
    "papermill": {
     "duration": 0.02848,
     "end_time": "2025-02-19T02:33:20.641426",
     "exception": false,
     "start_time": "2025-02-19T02:33:20.612946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_walks(generators , n_random_walk_length,  n_random_walks_to_generate,    state_rw_start = 'Auto',\n",
    "                 n_steps_back_to_ban = 0, walks_type = 'non-backtracking-beam',\n",
    "                 device='Auto', dtype = float , vec_hasher = 'Auto', verbose = 0   ):\n",
    "    '''\n",
    "    Output:\n",
    "    returns X,y: X - array of states, y - number of steps rw achieves it\n",
    "\n",
    "    Input:\n",
    "    generators - generators (moves) to make random walks  (permutations),\n",
    "        can be list of vectors or array with vstacked vectors\n",
    "    n_random_walk_length - number of visited nodes, i.e. number of steps + 1\n",
    "    n_random_walks_to_generate - how many random walks will run in parrallel\n",
    "    state_rw_start - initial states for random walks - by default we will use 0,1,2,3 ...\n",
    "        Can be vector or array\n",
    "        If it is vector it will be broadcasted n_random_walks_to_generate times,\n",
    "        If it is array n_random_walks_to_generate - input n_random_walks_to_generate will be ignored\n",
    "            and will be assigned: n_random_walks_to_generate = rw_start.shape[0]\n",
    "\n",
    "    '''\n",
    "    t0 = time.time()\n",
    "    ##########################################################################################\n",
    "    # Processing/Reformating input params\n",
    "    ##########################################################################################\n",
    "\n",
    "    # device\n",
    "    if device == 'Auto':\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "    # Analyse input format of \"generators\"\n",
    "    # can be list_generators, or tensor/np.array with rows - generators\n",
    "    if isinstance(generators, list):\n",
    "        list_generators = generators\n",
    "    elif isinstance(generators, tuple):\n",
    "        list_generators = list(generators)\n",
    "    elif isinstance(generators, torch.Tensor ):\n",
    "        list_generators = [ list(generators[i,:]) for i in range(generators.shape[0] ) ]\n",
    "    elif isinstance(generators, np.ndarray ):\n",
    "        list_generators = [list(generators[i,:]) for i in range(generators.shape[0] ) ]\n",
    "    else:\n",
    "        print('Unsupported format for \"generators\"', type(generators), generators)\n",
    "        raise ValueError('Unsupported format for \"generators\" ' + str(type(generators)) )\n",
    "    state_size = len(list_generators[0])\n",
    "    n_generators = len( list_generators )\n",
    "\n",
    "    # dtype\n",
    "    if (state_rw_start == '01234...') or (state_rw_start == 'Auto' ):\n",
    "        n_unique_symbols_in_states = state_size\n",
    "    else:\n",
    "        tmp = set( [int(i) for i in state_rw_start ]  ) # Number of unique elements in any iterator\n",
    "        n_unique_symbols_in_states = len(tmp)\n",
    "    if dtype == 'Auto':\n",
    "        if n_unique_symbols_in_states <= 256:\n",
    "            dtype = torch.uint8\n",
    "        else:\n",
    "            dtype = torch.uint16\n",
    "\n",
    "    # Destination state\n",
    "    if (state_rw_start == '01234...') or (state_rw_start == 'Auto' ):\n",
    "        state_rw_start = torch.arange( state_size, device=device, dtype = dtype).reshape(-1,state_size)\n",
    "    elif isinstance(state_destination, torch.Tensor ):\n",
    "        state_rw_start =  state_destination.to(device).to(dtype).reshape(-1,state_size)\n",
    "    else:\n",
    "        state_rw_start = torch.tensor( state_destination, device=device, dtype = dtype).reshape(-1,state_size)\n",
    "\n",
    "    # Reformat generators in torch 2d array\n",
    "    dtype_generators = torch.int64\n",
    "    tensor_generators = torch.tensor( list_generators , device = device, dtype =  dtype_generators  )\n",
    "    #print('tensor_generators.shape:', tensor_generators.shape)\n",
    "\n",
    "    # Preprare vector which will used for hashing - to avoid revisiting same states\n",
    "    max_int =  int( (2**62) )\n",
    "    dtype_for_hash = torch.int64\n",
    "    if vec_hasher == 'Auto':\n",
    "        vec_hasher = torch.randint(-max_int, max_int+1, size=(state_size,), device=device, dtype=dtype_for_hash)\n",
    "\n",
    "\n",
    "    ##########################################################################################\n",
    "    # Initializations\n",
    "    ##########################################################################################\n",
    "\n",
    "    # Main variable in the loop - store current states: 2d torch tensor\n",
    "    # Initialization via state_rw_start state - duplicatie it many (n_random_walks_to_generate) times\n",
    "    array_current_states = state_rw_start.view(1, state_size  ).expand(n_random_walks_to_generate, state_size ).clone()\n",
    "\n",
    "    # Output: X,y - states, y - how many steps we achieve them\n",
    "    # Allocate memory:\n",
    "    X = torch.zeros( (n_random_walks_to_generate)*n_random_walk_length , state_size, device=device, dtype = dtype )\n",
    "    y = torch.zeros( (n_random_walks_to_generate)*n_random_walk_length , device=device, dtype = dtype )\n",
    "    # First portion of data  - just our state_rw_start state  multiplexed many ( n_random_walks_to_generate ) times\n",
    "    X[:n_random_walks_to_generate,:] = array_current_states\n",
    "    y[:n_random_walks_to_generate] = 0\n",
    "\n",
    "    # Hash initial states.\n",
    "    if n_steps_back_to_ban > 0:\n",
    "        hash_initial_state = torch.sum( state_rw_start.view(-1, state_size  ) * vec_hasher, dim=1) # Compute hashes\n",
    "        vec_hashes_current = hash_initial_state.expand( n_random_walks_to_generate * n_generators  , n_steps_back_to_ban ).clone()\n",
    "        # That is equivalent to matmul, but matmul is not supported for ints in torch (on GPU <= 2018) - that is way round\n",
    "        # Intialize index for hash storage\n",
    "        # Newly obtained hash vectors will be stored in 2d array vec_hashes_current\n",
    "        # The position/column for storage: i_cyclic_index_for_hash_storage\n",
    "        i_cyclic_index_for_hash_storage = 0 # Will be updated modula n_steps_back_to_ban, i.e. from 0 to n_steps_back_to_ban-1\n",
    "\n",
    "\n",
    "    if verbose >= 100:\n",
    "        print('X.shape:',X.shape, 'y.shape:',y.shape)\n",
    "        print(array_current_states.shape)\n",
    "        print( array_current_states[:3,:] )\n",
    "\n",
    "    ##########################################################################################\n",
    "    # Main loop\n",
    "    # 1. Create new states from current making ALL possible moves - thus number of states will be more than we need\n",
    "    # 2. Select those states which were not visited on \"NNN\" previous steps. To make it fast we uses hashes:\n",
    "    # 2.1. Compute hashes of these states just by scalar multiplication on random hash vector - get single int64 as a hash\n",
    "    # 2.2. Choose only those states which hashes are new - not in the stored history of hashes\n",
    "    # 3. Select only desired number of states - random subset of desired size: n_random_walks_to_generate subset\n",
    "    # 4. Store these states into output X,y\n",
    "    # 5. Update hash storage\n",
    "    ##########################################################################################\n",
    "    for i_step in range(1,n_random_walk_length):\n",
    "        t_moves = t_hash = t_isin =  0; t_full_step = time.time() # Time profiling\n",
    "        t_unique_els = 0 # not used currently\n",
    "\n",
    "        # 1 Create new states:\n",
    "        # Apply all generators to all current states at once\n",
    "        # array_new_states: 2d array (n_random_walks_to_generate * n_generators  ) x state_size\n",
    "        t1 = time.time()\n",
    "        array_new_states = get_neighbors(array_current_states,tensor_generators  ).flatten(end_dim=1) # Flatten converts 3d array to 2d\n",
    "        t_moves += (time.time() - t1)\n",
    "\n",
    "        # 2.1 Compute hashes\n",
    "        # Compute hash. For non-backtracking - selection not visited states before.\n",
    "        t1 = time.time()\n",
    "        vec_hashes_new = torch.sum(array_new_states * vec_hasher, dim=1) # Compute hashes\n",
    "        # That is equivalent to matmul, but matmul is not supported for ints in torch (on GPU <= 2018) - that is way round\n",
    "        t_hash += (time.time() - t1)\n",
    "        #  print('hashed', t_hash )\n",
    "\n",
    "        if n_steps_back_to_ban > 0:\n",
    "            # 2.2 Select only states not seen before\n",
    "            # Nonbacktracking - select states not visited before\n",
    "            t1 = time.time()\n",
    "            mask_new = ~torch.isin(vec_hashes_new, vec_hashes_current.view(-1), assume_unique=False)\n",
    "            t_isin += (time.time() - t1)\n",
    "            mask_new_sum = mask_new.sum().item()\n",
    "            if mask_new_sum >= n_random_walks_to_generate:\n",
    "                # Select only new states - not visited before\n",
    "                array_new_states = array_new_states[mask_new,:]\n",
    "            else:\n",
    "                # Exceptional case - should not happen for large group of interest\n",
    "                # The case: can not find enough new states - will take old also not to crash the code\n",
    "                i_loc = n_random_walks_to_generate - mask_new_sum\n",
    "                array_new_states = torch.cat((array_new_states[mask_new,:], array_new_states[~mask_new,:][:i_loc,:]), dim=0)\n",
    "\n",
    "        # 3. Select only desired number of states\n",
    "        # Select only n_random_walks_to_generate (with preliminary shuffling)\n",
    "        # Update current states with them\n",
    "        perm = torch.randperm(array_new_states.size(0), device = device)\n",
    "        array_current_states = array_new_states[perm][:n_random_walks_to_generate]\n",
    "\n",
    "        # 4. Store results in final output\n",
    "        # print(i_step, n_random_walks_to_generate)\n",
    "        y[ (i_step)*n_random_walks_to_generate : (i_step+1)*n_random_walks_to_generate  ] = i_step\n",
    "        X[ (i_step)*n_random_walks_to_generate : (i_step+1)*n_random_walks_to_generate , : ] = array_current_states.float()\n",
    "\n",
    "        if n_steps_back_to_ban>0:\n",
    "            # 5. Update hash storage\n",
    "            # Pay attention - we store hashes for ALL obtained states not only for those selected - that gives us improvement:\n",
    "            # We improve the chances that states obtaine on i_step will be on true graph distance i_step - our ideal goal.\n",
    "            # Which might not always be the case since random walk may create loops.\n",
    "            # All the states which are achieved - they need not more than i_step steps - so it is better to ban them all\n",
    "            # Thus we improve chances that the next states will increase the true graph distance\n",
    "            i_cyclic_index_for_hash_storage = (i_cyclic_index_for_hash_storage + 1 ) % n_steps_back_to_ban\n",
    "            vec_hashes_current[:, i_cyclic_index_for_hash_storage ] = vec_hashes_new\n",
    "\n",
    "        if verbose >= 10:\n",
    "            t_full_step = time.time()-t_full_step\n",
    "            print(i_step,'i_step', 'array_current_states.shape:',array_current_states.shape, 'Time %.3f'%(time.time()-t0),\n",
    "                 't_moves  %.3f, t_hash  %.3f, t_isin %.3f, t_unique_els  %.3f, t_full_step %.3f'%(t_moves ,\n",
    "                  t_hash , t_isin , t_unique_els, t_full_step) )\n",
    "\n",
    "    return X,y\n",
    "def get_neighbors(states, moves):\n",
    "    \"\"\"\n",
    "    Some torch magic to apply all moves to all states at once\n",
    "    Input:\n",
    "    states: 2d torch array n_states x n_state_size - rows are states-vectors\n",
    "    moves (int64): 2d torch array n_moves x  n_state_size - rows are permutations describing moves\n",
    "    Returns:\n",
    "    3d tensor all moves applied to all states, shape: n_states x n_moves x n_state_size\n",
    "    Typically output is followed by .flatten(end_dim=1), which flattens to 2d array ( n_states * n_moves) x n_state_size\n",
    "    \"\"\"\n",
    "    return torch.gather(\n",
    "        states.unsqueeze(1).expand(states.size(0), moves.shape[0], states.size(1)),\n",
    "        2,\n",
    "        moves.unsqueeze(0).expand(states.size(0), moves.shape[0], states.size(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb84dedb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:20.653999Z",
     "iopub.status.busy": "2025-02-19T02:33:20.653592Z",
     "iopub.status.idle": "2025-02-19T02:33:20.938645Z",
     "shell.execute_reply": "2025-02-19T02:33:20.937933Z"
    },
    "papermill": {
     "duration": 0.293555,
     "end_time": "2025-02-19T02:33:20.940771",
     "exception": false,
     "start_time": "2025-02-19T02:33:20.647216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f01011d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:20.954199Z",
     "iopub.status.busy": "2025-02-19T02:33:20.953925Z",
     "iopub.status.idle": "2025-02-19T02:33:20.966480Z",
     "shell.execute_reply": "2025-02-19T02:33:20.965676Z"
    },
    "papermill": {
     "duration": 0.021053,
     "end_time": "2025-02-19T02:33:20.968180",
     "exception": false,
     "start_time": "2025-02-19T02:33:20.947127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MatrixDatasetRegrSmall(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.tensor(X, dtype=torch.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = F.one_hot(self.X[idx], num_classes=self.X.shape[1]).float()\n",
    "        return x.unsqueeze(0)\n",
    "\n",
    "class MyIntSequenceDatasetSmall(Dataset):\n",
    "    def __init__(self, X, is_regression=True):\n",
    "        # Store integer inputs and targets\n",
    "        dtype_y = torch.float32 if is_regression else torch.long\n",
    "        self.X = torch.tensor(X, dtype=torch.long)  # shape (N, 96)\n",
    "        \n",
    "        self.is_regression = is_regression\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return (input_sequence, target)\n",
    "        return self.X[idx]\n",
    "class MatrixDatasetRegr(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.int64)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = F.one_hot(self.X[idx], num_classes=self.X.shape[1]).float()\n",
    "        return x.unsqueeze(0), self.y[idx]\n",
    "\n",
    "class MyIntSequenceDataset(Dataset):\n",
    "    def __init__(self, X, y, is_regression=True):\n",
    "        # Store integer inputs and targets\n",
    "        dtype_y = torch.float32 if is_regression else torch.long\n",
    "        self.X = torch.tensor(X, dtype=torch.long)  # shape (N, 96)\n",
    "        self.y = torch.tensor(y, dtype=dtype_y)     # shape (N,)\n",
    "        \n",
    "        self.is_regression = is_regression\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return (input_sequence, target)\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def make_predictions_on_array(model, array):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    dataset = MyIntSequenceDatasetSmall(array)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for batch_X in loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    \n",
    "    return all_preds\n",
    "\n",
    "def calculate_metrics(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_targets.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(all_targets, all_preds))\n",
    "    r2 = r2_score(all_targets, all_preds)\n",
    "    \n",
    "    return rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "200fd6a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:20.980979Z",
     "iopub.status.busy": "2025-02-19T02:33:20.980737Z",
     "iopub.status.idle": "2025-02-19T02:33:20.988323Z",
     "shell.execute_reply": "2025-02-19T02:33:20.987654Z"
    },
    "papermill": {
     "duration": 0.015868,
     "end_time": "2025-02-19T02:33:20.989858",
     "exception": false,
     "start_time": "2025-02-19T02:33:20.973990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MatrixDatasetRegr(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.int64)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = F.one_hot(self.X[idx], num_classes=self.X.shape[1]).float()\n",
    "        return x.unsqueeze(0), self.y[idx]\n",
    "\n",
    "class MyIntSequenceDataset(Dataset):\n",
    "    def __init__(self, X, y, is_regression=True):\n",
    "        # Store integer inputs and targets\n",
    "        dtype_y = torch.float32 if is_regression else torch.long\n",
    "        self.X = X.to(torch.long)\n",
    "        self.y = y.to(dtype_y)\n",
    "#         self.X = torch.tensor(X, dtype=torch.long)  # shape (N, 96)\n",
    "#         self.y = torch.tensor(y, dtype=dtype_y)     # shape (N,)\n",
    "\n",
    "        self.is_regression = is_regression\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return (input_sequence, target)\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# train_dataset = MyIntSequenceDataset(X_train, y_train)\n",
    "# test_dataset = MyIntSequenceDataset(X_test, y_test)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "# model = CNNRegr().to(device)\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def calculate_metrics(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_targets.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(all_targets, all_preds))\n",
    "    r2 = r2_score(all_targets, all_preds)\n",
    "\n",
    "    return rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d4de50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:21.002359Z",
     "iopub.status.busy": "2025-02-19T02:33:21.002139Z",
     "iopub.status.idle": "2025-02-19T02:33:21.010653Z",
     "shell.execute_reply": "2025-02-19T02:33:21.009928Z"
    },
    "papermill": {
     "duration": 0.016654,
     "end_time": "2025-02-19T02:33:21.012265",
     "exception": false,
     "start_time": "2025-02-19T02:33:20.995611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from datetime import datetime\n",
    "def train(num_epochs=2, model_prefix='', batch_size=128, patience=5):\n",
    "  # Training loop\n",
    "  train_rmse_list, train_r2_list = [], []\n",
    "  test_rmse_list, test_r2_list = [], []\n",
    "  loss_list = []\n",
    "\n",
    "\n",
    "  best_test_rmse = float('inf')\n",
    "  patience = patience\n",
    "  no_improve = 0\n",
    "  best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "      X_train, y_train = random_walks(list_generators, n_random_walk_length,  n_random_walks_to_generate,\n",
    "                                     n_steps_back_to_ban=8)\n",
    "\n",
    "      train_dataset = MyIntSequenceDataset(X_train, y_train)\n",
    "      train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "      model.train()\n",
    "      for batch_X, batch_y in train_loader:\n",
    "          batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(batch_X)\n",
    "          loss = criterion(outputs, batch_y)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "      # Calculate metrics for train and test data\n",
    "      train_rmse, train_r2 = calculate_metrics(model, train_loader)\n",
    "      test_rmse, test_r2 = calculate_metrics(model, test_loader)\n",
    "      train_rmse_list.append(train_rmse)\n",
    "      train_r2_list.append(train_r2)\n",
    "      test_rmse_list.append(test_rmse)\n",
    "      test_r2_list.append(test_r2)\n",
    "\n",
    "      scheduler.step(test_rmse)\n",
    "\n",
    "      print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Time: {str(datetime.now())}')\n",
    "      print(f'Train - RMSE: {train_rmse:.4f}, R²: {train_r2:.4f}')\n",
    "      print(f'Test  - RMSE: {test_rmse:.4f}, R²: {test_r2:.4f}')\n",
    "      del train_dataset, train_loader\n",
    "      gc.collect()\n",
    "      # Early stopping\n",
    "      if test_rmse < best_test_rmse:\n",
    "          best_test_rmse = test_rmse\n",
    "          no_improve = 0\n",
    "          torch.save(model.state_dict(), f'best_model_{model_prefix}_{best_test_rmse}.pth')\n",
    "          best_model_weights = copy.deepcopy(model.state_dict())\n",
    "      else:\n",
    "          no_improve += 1\n",
    "          if no_improve == patience:\n",
    "              print(\"Early stopping triggered\")\n",
    "              break\n",
    "  print('Finished Training')\n",
    "  print(f'Best metrics: {min(test_rmse_list)=:.4f} {max(test_r2_list)=:.4f}')\n",
    "  model.load_state_dict(best_model_weights)\n",
    "  return model, train_rmse_list, train_r2_list, test_rmse_list, test_r2_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ebf5259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:21.024842Z",
     "iopub.status.busy": "2025-02-19T02:33:21.024625Z",
     "iopub.status.idle": "2025-02-19T02:33:21.029781Z",
     "shell.execute_reply": "2025-02-19T02:33:21.029086Z"
    },
    "papermill": {
     "duration": 0.013291,
     "end_time": "2025-02-19T02:33:21.031398",
     "exception": false,
     "start_time": "2025-02-19T02:33:21.018107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_S_N(N):\n",
    "    return [\n",
    "        [1,0,]+[q+2 for q in range(N-2)]       ,\n",
    "               [q+1 for q in range(N-1)] + [0,],\n",
    "        [N-1,]+[q+0 for q in range(N-1)]       ,\n",
    "    ]\n",
    "\n",
    "\n",
    "def make_predictions_on_array(model, array):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    dataset = MyIntSequenceDatasetSmall(array)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for batch_X in loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3de16307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:21.044553Z",
     "iopub.status.busy": "2025-02-19T02:33:21.044207Z",
     "iopub.status.idle": "2025-02-19T02:33:21.057856Z",
     "shell.execute_reply": "2025-02-19T02:33:21.057255Z"
    },
    "papermill": {
     "duration": 0.022188,
     "end_time": "2025-02-19T02:33:21.059418",
     "exception": false,
     "start_time": "2025-02-19T02:33:21.037230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def beam_search_sorting(permutation, beam_width=5):\n",
    "    n = len(permutation)\n",
    "    target = list(range(0, n))\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def average_neighbor_difference(perm):\n",
    "        total_diff = 0\n",
    "\n",
    "        # Считаем разницы между соседними элементами\n",
    "        for i in range(n-1):\n",
    "            total_diff += abs(perm[i] - perm[i+1])\n",
    "\n",
    "        # Добавляем разницу между последним и первым элементом\n",
    "        total_diff += abs(perm[-1] - perm[0])\n",
    "\n",
    "        return total_diff / n\n",
    "\n",
    "    def count_monotonic_sections(perm):\n",
    "        # Создаем расширенную перестановку для учета цикличности\n",
    "        extended_perm = perm + perm[0:1]\n",
    "\n",
    "        sections = 0\n",
    "        increasing = None\n",
    "\n",
    "        for i in range(n):\n",
    "            if increasing is None:  # Первое сравнение\n",
    "                increasing = extended_perm[i] < extended_perm[i + 1]\n",
    "            elif increasing and extended_perm[i] > extended_perm[i + 1]:  # Смена возрастания на убывание\n",
    "                sections += 1\n",
    "                increasing = False\n",
    "            elif not increasing and extended_perm[i] < extended_perm[i + 1]:  # Смена убывания на возрастание\n",
    "                sections += 1\n",
    "                increasing = True\n",
    "\n",
    "        return sections / n\n",
    "\n",
    "    def apply_actions(state):\n",
    "        # Generate new states based on the allowed actions\n",
    "        states = []\n",
    "        # 1. Cyclic shift right\n",
    "        new_state = state[-1:] + state[:-1]\n",
    "        states.append((new_state, \"R\"))\n",
    "\n",
    "        # 2. Cyclic shift left\n",
    "        new_state = state[1:] + state[:1]\n",
    "        states.append((new_state, \"L\"))\n",
    "\n",
    "        # 3. Swap first two elements\n",
    "        if len(state) > 1:\n",
    "            new_state = state[:]\n",
    "            new_state[0], new_state[1] = new_state[1], new_state[0]\n",
    "            states.append((new_state, \"X\"))\n",
    "\n",
    "        return states\n",
    "\n",
    "    def apply_action(state, action):\n",
    "        # 1. Cyclic shift right\n",
    "        if action == 'R':\n",
    "            new_state = state[-1:] + state[:-1]\n",
    "            return new_state\n",
    "        elif action == 'L':\n",
    "            # 2. Cyclic shift left\n",
    "            new_state = state[1:] + state[:1]\n",
    "            return new_state\n",
    "\n",
    "        new_state = state[:]\n",
    "        new_state[0], new_state[1] = new_state[1], new_state[0]\n",
    "        return new_state\n",
    "\n",
    "\n",
    "    # Priority queue for the beam search; stores tuples of (cumulative cost, path, current state)\n",
    "    queue = deque([(0, [], permutation)])\n",
    "    seen = set()\n",
    "\n",
    "    max_actions = 0\n",
    "    q_values = []\n",
    "\n",
    "    while queue:\n",
    "        # Limit the size of the queue as per beam width\n",
    "        queue = deque(sorted(list(queue), key=lambda x: x[0])[:beam_width])\n",
    "        next_queue = deque()\n",
    "\n",
    "        for cost, path, current in queue:\n",
    "            if len(path) > max_actions:\n",
    "                max_actions = len(path)\n",
    "                if max_actions % 100 == 0:\n",
    "                    print('new max len', len(path), len(queue), len(seen), np.min(q_values))\n",
    "                q_values = []\n",
    "            if len(path) > 40000:\n",
    "                #print('long path', queue)\n",
    "                return None\n",
    "            if current == target:\n",
    "                return path  # Return the path to sorted order\n",
    "\n",
    "\n",
    "            for action in ['L','R','X']:\n",
    "                if action == 'L' and len(path) > 0 and path[-1] == 'R':\n",
    "                    continue\n",
    "                if action == 'R' and len(path) > 0 and path[-1] == 'L':\n",
    "                    continue\n",
    "                if action == 'X' and current[0] < current[1]:\n",
    "                    continue\n",
    "\n",
    "                next_state = apply_action(current, action)\n",
    "\n",
    "                if tuple(next_state) not in seen:\n",
    "                    seen.add(tuple(next_state))\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        t_state = torch.FloatTensor(next_state).unsqueeze(0).to(device)\n",
    "                        q_value = make_predictions_on_array(model, t_state.cpu().numpy() )\n",
    "                        # q_value = model(t_state).squeeze().item()\n",
    "                        q_values.append(q_value)\n",
    "\n",
    "                    total_cost = cost + 1 + q_value\n",
    "                    next_queue.append((total_cost, path + [action], next_state))\n",
    "\n",
    "        queue = next_queue\n",
    "\n",
    "    return None  # Return None if no solution is found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0bf94d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:21.071864Z",
     "iopub.status.busy": "2025-02-19T02:33:21.071651Z",
     "iopub.status.idle": "2025-02-19T02:33:21.082722Z",
     "shell.execute_reply": "2025-02-19T02:33:21.082065Z"
    },
    "papermill": {
     "duration": 0.019162,
     "end_time": "2025-02-19T02:33:21.084274",
     "exception": false,
     "start_time": "2025-02-19T02:33:21.065112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GatedResidualBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    A 1D TCN block with gated activation:\n",
    "      - Conv1D (dilation) -> BN -> [sigmoid gate * tanh candidate] -> Dropout -> Conv1D ...\n",
    "      - Residual skip\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        pad = (kernel_size - 1) * dilation // 2\n",
    "\n",
    "        # First conv for the gated activation\n",
    "        self.conv_filter = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                                     padding=pad, dilation=dilation)\n",
    "        self.conv_gate   = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                                     padding=pad, dilation=dilation)\n",
    "        self.bn_filter = nn.BatchNorm1d(out_channels)\n",
    "        self.bn_gate   = nn.BatchNorm1d(out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Second conv\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                               padding=pad, dilation=dilation)\n",
    "        self.bn2   = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.shortcut = None\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv1d(in_channels, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        # Gated activation\n",
    "        filter_out = self.conv_filter(x)\n",
    "        filter_out = self.bn_filter(filter_out)\n",
    "        gate_out   = self.conv_gate(x)\n",
    "        gate_out   = self.bn_gate(gate_out)\n",
    "\n",
    "        filter_out = torch.tanh(filter_out)\n",
    "        gate_out   = torch.sigmoid(gate_out)\n",
    "        out = filter_out * gate_out  # gating\n",
    "\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # Second conv\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Residual\n",
    "        if self.shortcut is not None:\n",
    "            residual = self.shortcut(residual)\n",
    "\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class GatedTCN1D(nn.Module):\n",
    "    \"\"\"\n",
    "    An improved TCN for 1D sequences using gated residual blocks.\n",
    "      1) Embedding (if needed)\n",
    "      2) Stacked GatedResidualBlock1D with dilations 1, 2, 4, ...\n",
    "      3) Global pool\n",
    "      4) FC for output\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 vocab_size=50,\n",
    "                 embed_dim=32,\n",
    "                 hidden_dim=128,\n",
    "                 num_levels=4,\n",
    "                 kernel_size=3,\n",
    "                 dropout=0.3,\n",
    "                 out_dim=1):\n",
    "        super().__init__()\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        # Embedding for integer tokens\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.proj = nn.Conv1d(embed_dim, hidden_dim, kernel_size=1)\n",
    "\n",
    "        # Build stacked blocks with growing dilation\n",
    "        self.blocks = nn.ModuleList()\n",
    "        dilation = 1\n",
    "        for _ in range(num_levels):\n",
    "            block = GatedResidualBlock1D(\n",
    "                in_channels=hidden_dim,\n",
    "                out_channels=hidden_dim,\n",
    "                kernel_size=kernel_size,\n",
    "                dilation=dilation,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            self.blocks.append(block)\n",
    "            dilation *= 2\n",
    "\n",
    "        # Global pooling\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # Final linear\n",
    "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len) integer tokens\n",
    "        \"\"\"\n",
    "        # 1) Embedding -> (batch, seq_len, embed_dim)\n",
    "        x = self.embedding(x)\n",
    "        # 2) => (batch, embed_dim, seq_len)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # 3) Project to hidden_dim\n",
    "        x = self.proj(x)\n",
    "\n",
    "        # 4) Pass through each gated TCN block\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        # 5) Global pool => (batch, hidden_dim, 1)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.squeeze(-1)  # => (batch, hidden_dim)\n",
    "\n",
    "        # 6) Output\n",
    "        out = self.fc(x)\n",
    "        if self.out_dim == 1:\n",
    "            out = out.squeeze(-1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55dbd2c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:21.096831Z",
     "iopub.status.busy": "2025-02-19T02:33:21.096594Z",
     "iopub.status.idle": "2025-02-19T02:33:21.823180Z",
     "shell.execute_reply": "2025-02-19T02:33:21.822210Z"
    },
    "papermill": {
     "duration": 0.734791,
     "end_time": "2025-02-19T02:33:21.824957",
     "exception": false,
     "start_time": "2025-02-19T02:33:21.090166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120000, 16])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "dimension = 16\n",
    "dic={5: 20,\n",
    "     10: 140,\n",
    "     16: 180,\n",
    "    20:\t250,\n",
    "21:\t273,\n",
    "22:\t297,\n",
    "23:\t322,\n",
    "24:\t348,\n",
    "25:\t375,\n",
    "26:\t403,\n",
    "27:\t432,\n",
    "28:\t462,\n",
    "29:\t493,\n",
    "30:\t525,\n",
    "31:\t558,\n",
    "32:\t592,\n",
    "35:\t700,\n",
    "37:\t777,\n",
    "40:\t900,\n",
    "45:\t1125,\n",
    "50:\t1375,\n",
    "60:\t1950,\n",
    "70:\t2625,\n",
    "80:\t3400,\n",
    "90:\t4275,\n",
    "100: 5250,\n",
    "150:\t11625,\n",
    "200:\t20500,\n",
    "300:\t45750}\n",
    "n_random_walk_length = dic[dimension]\n",
    "rate_of_diffusion_distance =10\n",
    "n_random_walk_length = n_random_walk_length*rate_of_diffusion_distance\n",
    "n_random_walk_length = 120\n",
    "n_random_walks_to_generate_validation_fixed = 100\n",
    "# n_random_walk_length = 40\n",
    "n_random_walks_to_generate = 1000\n",
    "\n",
    "list_generators = make_S_N(dimension)\n",
    "# X_test, y_test = random_walks(n_random_walk_length,  n_random_walks_to_generate)\n",
    "X_test, y_test = random_walks(list_generators, n_random_walk_length,  n_random_walks_to_generate,n_steps_back_to_ban=8)\n",
    "print(X_test.shape)\n",
    "test_dataset = MyIntSequenceDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "p = np.arange(dimension)\n",
    "n = dimension\n",
    "p[0], p[1] = p[1], p[0]\n",
    "i = 2\n",
    "while i < n-i+1:\n",
    "    p[i], p[n-i+1] = p[n-i+1], p[i]\n",
    "    i += 1\n",
    "permutation = p.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcde79e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:21.839462Z",
     "iopub.status.busy": "2025-02-19T02:33:21.839152Z",
     "iopub.status.idle": "2025-02-19T02:33:44.050004Z",
     "shell.execute_reply": "2025-02-19T02:33:44.049100Z"
    },
    "papermill": {
     "duration": 22.219672,
     "end_time": "2025-02-19T02:33:44.051757",
     "exception": false,
     "start_time": "2025-02-19T02:33:21.832085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 0.001409\n",
      "Epoch [1/2], Loss: 658.4556, Time: 2025-02-19 02:33:33.905445\n",
      "Train - RMSE: 22.2457, R²: 0.5876\n",
      "Test  - RMSE: 22.8087, R²: 0.5664\n",
      "Epoch [2/2], Loss: 595.7567, Time: 2025-02-19 02:33:43.920266\n",
      "Train - RMSE: 19.1201, R²: 0.6953\n",
      "Test  - RMSE: 21.1753, R²: 0.6263\n",
      "Finished Training\n",
      "Best metrics: min(test_rmse_list)=21.1753 max(test_r2_list)=0.6263\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = GatedTCN1D(vocab_size=dimension,\n",
    "                           embed_dim=4,\n",
    "                           hidden_dim=8,\n",
    "                           num_levels=2,\n",
    "                           kernel_size=3,\n",
    "                           dropout=0.3,\n",
    "                           out_dim=1).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.8, verbose=True)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1000000\n",
    "print(f'Total trainable parameters: {pytorch_total_params}')\n",
    "# print(str(datetime.now()))\n",
    "model, train_rmse_list, train_r2_list, test_rmse_list, test_r2_list, loss_list = train(2, f'{dimension}_GatedTCN1D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a8b68",
   "metadata": {
    "papermill": {
     "duration": 0.006277,
     "end_time": "2025-02-19T02:33:44.064368",
     "exception": false,
     "start_time": "2025-02-19T02:33:44.058091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eab9462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:44.077997Z",
     "iopub.status.busy": "2025-02-19T02:33:44.077593Z",
     "iopub.status.idle": "2025-02-19T02:33:51.446502Z",
     "shell.execute_reply": "2025-02-19T02:33:51.445517Z"
    },
    "papermill": {
     "duration": 7.377537,
     "end_time": "2025-02-19T02:33:51.448284",
     "exception": false,
     "start_time": "2025-02-19T02:33:44.070747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new max len 100 10 1591 43.345562\n",
      "new max len 200 10 2999 28.314468\n",
      "new max len 300 10 4452 10.886448\n",
      "Кратчайший путь: 316\n",
      "['X', 'R', 'X', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'R', 'X', 'R', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'R', 'R', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L']\n",
      "7 seconds passed\n"
     ]
    }
   ],
   "source": [
    "model.to(device);\n",
    "a = datetime.now()\n",
    "k = 10  # Ширина \"луча\"\n",
    "path = beam_search_sorting(permutation, beam_width=k)\n",
    "if path:\n",
    "    print(\"Кратчайший путь:\", len(path))\n",
    "    print(path)\n",
    "else:\n",
    "    print('No path found')\n",
    "d = (datetime.now() - a).seconds\n",
    "print(f'{d} seconds passed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a61e024e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:51.462476Z",
     "iopub.status.busy": "2025-02-19T02:33:51.462166Z",
     "iopub.status.idle": "2025-02-19T02:33:53.108299Z",
     "shell.execute_reply": "2025-02-19T02:33:53.107252Z"
    },
    "papermill": {
     "duration": 1.655634,
     "end_time": "2025-02-19T02:33:53.110537",
     "exception": false,
     "start_time": "2025-02-19T02:33:51.454903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cayleypy'...\r\n",
      "remote: Enumerating objects: 67, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (67/67), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (44/44), done.\u001b[K\r\n",
      "remote: Total 67 (delta 42), reused 47 (delta 22), pack-reused 0 (from 0)\u001b[K\r\n",
      "Unpacking objects: 100% (67/67), 34.69 KiB | 740.00 KiB/s, done.\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbbfdecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:53.125819Z",
     "iopub.status.busy": "2025-02-19T02:33:53.125523Z",
     "iopub.status.idle": "2025-02-19T02:33:53.135890Z",
     "shell.execute_reply": "2025-02-19T02:33:53.135020Z"
    },
    "papermill": {
     "duration": 0.020221,
     "end_time": "2025-02-19T02:33:53.137646",
     "exception": false,
     "start_time": "2025-02-19T02:33:53.117425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:16,e0+1000=1000,r168.\n"
     ]
    }
   ],
   "source": [
    "dimension=16\n",
    "rate_of_diffusion_distance =1\n",
    "CFG = { 'dimension'                       :    dimension,     # N\n",
    "        'generators_family'               : 'S_N',\n",
    "        'n_epochs'                        :  1000//rate_of_diffusion_distance *5,     #41,\n",
    "        'epochs_start'                    :  0,\n",
    "        'lr'                              :  0.000001,\n",
    "        'range_of_cubies'                 :  100 ,\n",
    "       \n",
    "        ### adavanced beam search params\n",
    "        'beam_width'                      : 2**17 , #100k\n",
    "        'random_walks'                    : 10000 ,   #10k\n",
    "       \n",
    "        'n_steps_limit'                   : dimension*rate_of_diffusion_distance*4   ,\n",
    "        'n_step_size'                     : 1     , \n",
    "        'n_beam_candidate_states'         : 'Auto',\n",
    "        'radius_destination_neigbourhood' : 5     ,\n",
    "        'radius_beam_neigbourhood'        : 0     , # not used actually\n",
    "        'bi_bfs_chunk_size_states'        : 2**16 , # not used actually  2**16\n",
    "        'mode_bibfs_checks'               : (10,5), # not used actually\n",
    "        'temperature'                     : 0     ,\n",
    "        'temperature_decay'               : 1     ,\n",
    "        'alpha_past_states_attenuation'   : 0     ,\n",
    "        'n_steps_to_ban_backtracking'     : 100     ,\n",
    "        'flag_empty_backtracking_list'    : False ,\n",
    "        'n_attempts_limit'                : 1     ,\n",
    "        'do_check_stagnation'             : False , \n",
    "        'stagnation_steps'                : 0    ,\n",
    "        'stagnation_thres'                : 0.005 ,\n",
    "        'n_random_start_steps'            : 0     ,\n",
    "        'diversity_func'                  : None,\n",
    "        'diversity_weight'                : None     ,\n",
    "        'sub_ray_split'                   : False ,\n",
    "        #'random_seed'                     : -23057572\n",
    "\n",
    "\n",
    "        ### train params\n",
    "        #'n_random_walk_length'                                :    ,\n",
    "        'n_random_walks_to_generate'                          : 1000,\n",
    "        'n_random_walks_to_generate_validation_new_each_epoch': 100 ,\n",
    "        'n_random_walks_to_generate_validation_fixed'         : 100 ,\n",
    "        'batch_size'                                          : 256 ,\n",
    "        'list_epochs_to_save_predictions_and_errors'          : [1,2,4,8,16,32,64,100],\n",
    "      }\n",
    "\n",
    "dic={16:\t168,\n",
    "17:\t187,\n",
    "18:\t207,\n",
    "19:\t228,\n",
    "20:\t250,\n",
    "21:\t273,\n",
    "22:\t297,\n",
    "23:\t322,\n",
    "24:\t348,\n",
    "25:\t375,\n",
    "26:\t403,\n",
    "27:\t432,\n",
    "28:\t462,\n",
    "29:\t493,\n",
    "30:\t525,\n",
    "31:\t558,\n",
    "32:\t592,\n",
    "33:\t627,\n",
    "34:\t663,\n",
    "35:\t700,\n",
    "36:\t738,\n",
    "37:\t777,\n",
    "38:\t817,\n",
    "39:\t858,\n",
    "40:\t900,\n",
    "41:\t943,\n",
    "42:\t987,\n",
    "43:\t1032,\n",
    "44:\t1078,\n",
    "45:\t1125,\n",
    "46:\t1173,\n",
    "47:\t1222,\n",
    "48:\t1272,\n",
    "49:\t1323,\n",
    "50:\t1375}\n",
    "n_random_walk_length=dic[dimension]\n",
    "CFG['n_random_walk_length'] = n_random_walk_length #(CFG['dimension']*(CFG['dimension']-1)//2 ) + CFG['dimension']*3\n",
    "print(f\"Version:{dimension},e{CFG['epochs_start']}+{1000//rate_of_diffusion_distance}={CFG['epochs_start']+1000//rate_of_diffusion_distance},r{n_random_walk_length*rate_of_diffusion_distance}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8310812f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:53.152638Z",
     "iopub.status.busy": "2025-02-19T02:33:53.151918Z",
     "iopub.status.idle": "2025-02-19T02:33:53.157406Z",
     "shell.execute_reply": "2025-02-19T02:33:53.156634Z"
    },
    "papermill": {
     "duration": 0.014682,
     "end_time": "2025-02-19T02:33:53.159024",
     "exception": false,
     "start_time": "2025-02-19T02:33:53.144342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cb434cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:53.173862Z",
     "iopub.status.busy": "2025-02-19T02:33:53.173598Z",
     "iopub.status.idle": "2025-02-19T02:33:53.179499Z",
     "shell.execute_reply": "2025-02-19T02:33:53.178635Z"
    },
    "papermill": {
     "duration": 0.015184,
     "end_time": "2025-02-19T02:33:53.181136",
     "exception": false,
     "start_time": "2025-02-19T02:33:53.165952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def state_from_code(N, moves):\n",
    "    \n",
    "        moves_cleanup = [(q[0],q[1]) if q[0]<q[1] else (q[1],q[0]) for q in moves if q[0]!=q[1]]\n",
    "        moves_cleanup = list(dict.fromkeys(moves_cleanup,None).keys())\n",
    "        \n",
    "        res = list(range(N))\n",
    "        for i,j in moves_cleanup:\n",
    "            res[i],res[j] = res[j],res[i]\n",
    "    \n",
    "        return res\n",
    "    \n",
    "sts1 = state_from_code(CFG['dimension'], moves = [(0,1),]+[(q+2,CFG['dimension']-q-1) for q in range(CFG['dimension']//2)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62f8310f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:53.196440Z",
     "iopub.status.busy": "2025-02-19T02:33:53.195792Z",
     "iopub.status.idle": "2025-02-19T02:33:53.199565Z",
     "shell.execute_reply": "2025-02-19T02:33:53.198879Z"
    },
    "papermill": {
     "duration": 0.013358,
     "end_time": "2025-02-19T02:33:53.201219",
     "exception": false,
     "start_time": "2025-02-19T02:33:53.187861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sts = sts1\n",
    "params  = [(0,0)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb11d2f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:53.216159Z",
     "iopub.status.busy": "2025-02-19T02:33:53.215873Z",
     "iopub.status.idle": "2025-02-19T02:33:53.220159Z",
     "shell.execute_reply": "2025-02-19T02:33:53.219373Z"
    },
    "papermill": {
     "duration": 0.013786,
     "end_time": "2025-02-19T02:33:53.221805",
     "exception": false,
     "start_time": "2025-02-19T02:33:53.208019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from cayleypy.cayleypy import *\n",
    "# def make_S_N(N):\n",
    "#     return [\n",
    "#         [1,0,]+[q+2 for q in range(N-2)]       ,\n",
    "#                [q+1 for q in range(N-1)] + [0,],\n",
    "#         [N-1,]+[q+0 for q in range(N-1)]       ,\n",
    "#     ]\n",
    "\n",
    "# def make_permutohedron(N):\n",
    "#     return [\n",
    "#         list(range(0,i)) + [i+1,i,] + list(range(i+2,N)) for i in range(N-1)\n",
    "#     ]# + [[N-1,]+list(range(1,N-1))+[0,]]\n",
    "\n",
    "# def make_all_pair_perms(N):\n",
    "#     res = []\n",
    "\n",
    "#     for i in range(N):\n",
    "#         for j in range(N):\n",
    "#             candidate = list(range(N))\n",
    "#             if i!=j:\n",
    "#                 candidate[i] = j\n",
    "#                 candidate[j] = i\n",
    "#                 res.append(tuple(candidate))\n",
    "    \n",
    "#     return res\n",
    "\n",
    "# def make_pancake(N):\n",
    "#     return [\n",
    "#         list(range(i,-1,-1)) + list(range(i+1, N)) for i in range(1,N)\n",
    "#     ]\n",
    "# def is_1_neighbour(cg, state1, state2):\n",
    "#     state1_neighbours = get_neighbors2(state1, cg.tensor_generators )\n",
    "#     for i in range(state1_neighbours.shape[0]):\n",
    "#         if torch.allclose(state1_neighbours[i,:], state2):\n",
    "#             return i, state1_neighbours[i:i+1,:]\n",
    "#     return -1, None\n",
    "\n",
    "# def make_unique_path_from_path_states(cg, path_states):\n",
    "#     res_mvs = []\n",
    "#     res_sts = [path_states[0][0:1,:].detach().clone(),]\n",
    "    \n",
    "#     ps0 = path_states[0][0:1,:].detach().clone()\n",
    "#     for ps1 in path_states[1:]:\n",
    "#         for ps1_i in range(ps1.shape[0]):\n",
    "#             m,s = is_1_neighbour(cg, ps0, ps1[ps1_i:ps1_i+1],)\n",
    "#             if m>-1:\n",
    "#                 res_mvs.append(m)\n",
    "#                 res_sts.append(s.detach().clone())\n",
    "#                 ps0 = s.detach().clone()\n",
    "#                 break\n",
    "\n",
    "#     return torch.vstack(res_sts), res_mvs\n",
    "\n",
    "# families = {'S_N':make_S_N,\n",
    "#             'PHD':make_permutohedron,\n",
    "#             'PRS':make_all_pair_perms,\n",
    "#             'PNC':make_pancake,}\n",
    "# list_generators = families[CFG['generators_family']](CFG['dimension'])\n",
    "# cayley_group = CayleyGraph( list_generators , dtype=torch.long)\n",
    "# cayley_group.state_destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd8a4833",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:53.238859Z",
     "iopub.status.busy": "2025-02-19T02:33:53.238138Z",
     "iopub.status.idle": "2025-02-19T02:33:53.244267Z",
     "shell.execute_reply": "2025-02-19T02:33:53.243603Z"
    },
    "papermill": {
     "duration": 0.015445,
     "end_time": "2025-02-19T02:33:53.245915",
     "exception": false,
     "start_time": "2025-02-19T02:33:53.230470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_return=False\n",
    "model = model.half()\n",
    "model.dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04cfb646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T02:33:53.260671Z",
     "iopub.status.busy": "2025-02-19T02:33:53.260411Z",
     "iopub.status.idle": "2025-02-19T02:33:53.265742Z",
     "shell.execute_reply": "2025-02-19T02:33:53.264991Z"
    },
    "papermill": {
     "duration": 0.014622,
     "end_time": "2025-02-19T02:33:53.267310",
     "exception": false,
     "start_time": "2025-02-19T02:33:53.252688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dict_additional_data = dict()\n",
    "\n",
    "# rdn, nbt = params[0] \n",
    "\n",
    "# flag_found_destination, i_step, dict_additional_data  =\\\n",
    "#      cayley_group.beam_search_permutations_torch(\n",
    "#          state_start                     = sts                                   ,\n",
    "#          models_or_heuristics            = model                                ,\n",
    "\n",
    "#          beam_width                      = CFG ['beam_width'],\n",
    "#          n_steps_limit                   = CFG ['dimension']*CFG ['dimension'] + CFG ['dimension']*3, #1700,#min(A[enum]//2, 600), #CFG[\"n_steps_limit\"                  ],\n",
    "#          n_step_size                     = CFG[\"n_step_size\"                    ],\n",
    "#          n_beam_candidate_states         = CFG[\"n_beam_candidate_states\"        ],\n",
    "\n",
    "#          radius_destination_neigbourhood = 21, #rdn, #CFG[\"radius_destination_neigbourhood\"],\n",
    "\n",
    "#          radius_beam_neigbourhood        = CFG[\"radius_beam_neigbourhood\"       ],\n",
    "#          bi_bfs_chunk_size_states        = CFG[\"bi_bfs_chunk_size_states\"       ],\n",
    "#          mode_bibfs_checks               = CFG[\"mode_bibfs_checks\"              ],\n",
    "#          temperature                     = CFG[\"temperature\"                    ],\n",
    "#          alpha_past_states_attenuation   = CFG[\"alpha_past_states_attenuation\"  ],\n",
    "\n",
    "#          n_steps_to_ban_backtracking     = nbt, #CFG[\"n_steps_to_ban_backtracking\"    ],\n",
    "\n",
    "#          flag_empty_backtracking_list    = CFG[\"flag_empty_backtracking_list\"   ],\n",
    "#          n_attempts_limit                = CFG[\"n_attempts_limit\"               ],\n",
    "#          do_check_stagnation             = CFG[\"do_check_stagnation\"            ],\n",
    "#          stagnation_steps                = CFG[\"stagnation_steps\"               ],\n",
    "#          stagnation_thres                = CFG[\"stagnation_thres\"               ],\n",
    "#          n_random_start_steps            = CFG[\"n_random_start_steps\"           ],\n",
    "#          diversity_func                  = CFG['diversity_func'                 ],\n",
    "#          diversity_weight                = CFG['diversity_weight'               ],\n",
    "#          sub_ray_split                   = CFG['sub_ray_split'                  ],\n",
    "\n",
    "#          verbose                         = -1,\n",
    "#          random_seed                     = dict_additional_data.get('random_seed',None),\n",
    "#          flag_path_return                = path_return, #False,#True,\n",
    "#        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if flag_found_destination:\n",
    "#     if path_return==True:\n",
    "#         A, path_moves = make_unique_path_from_path_states(cayley_group, dict_additional_data[\"path_states\"] )\n",
    "#         moves_mapping = {0:'X',1:'R',2:'L'}\n",
    "#         moves_res = ''.join(reversed([moves_mapping[q] for q in path_moves]))\n",
    "#     else: \n",
    "#         moves_res = ''\n",
    "# #     print(       f'True: epoch:{epoch};   flag_found_destination: {flag_found_destination}; i_step: {i_step};  beam_width:{CFG [\"beam_width\"]}; dim:{CFG[\"dimension\"]};;moves_res:{moves_res}')\n",
    "# #     logging.info(f'True: epoch:{epoch}:   flag_found_destination: {flag_found_destination}; i_step: {i_step};  beam_width:{CFG [\"beam_width\"]}; dim:{CFG[\"dimension\"]}; seed:{dict_additional_data.get('random_seed',None)};moves_res:{moves_res}')\n",
    "# # else:\n",
    "# #     print(       f'False: epoch:{epoch};  flag_found_destination: {flag_found_destination}; i_step: {7777777};  beam_width:{CFG [\"beam_width\"]}; dim:{CFG[\"dimension\"]}; seed:{dict_additional_data.get('random_seed',None)}; sts: {sts};')                                        \n",
    "# #     logging.info(f'False: epoch:{epoch};  flag_found_destination: {flag_found_destination}; i_step: {7777777};  beam_width:{CFG [\"beam_width\"]}; dim:{CFG[\"dimension\"]}; seed:{dict_additional_data.get('random_seed',None)}; sts: {sts};')   \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11024468,
     "sourceId": 92501,
     "sourceType": "competition"
    },
    {
     "datasetId": 4441442,
     "sourceId": 9604131,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 43.969806,
   "end_time": "2025-02-19T02:33:54.996286",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-19T02:33:11.026480",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
