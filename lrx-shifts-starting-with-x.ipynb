{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e561b354",
   "metadata": {
    "papermill": {
     "duration": 0.002721,
     "end_time": "2025-02-17T02:32:57.573766",
     "exception": false,
     "start_time": "2025-02-17T02:32:57.571045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## What is it about\n",
    "\n",
    "Taking small $n$ ($3\\leqslant n \\leqslant 8$), for each permutation $\\pi \\in S_n$ find a sequence $M$ of moves **L** (cyclic shift to the left), **R** (cyclic shift to the right), **X** (transposition of the first to elements) which converts $\\pi$ to the identity permutation. Then if $M$ starts with **X**, find sequences which solve $L^{k}\\pi$ for all $k = 1, \\ldots, n-1$. The hypothesis is that the lengths of solving sequences for each pair $L^{k}\\pi$, $L^{k+1}\\pi$ are different. According to the calculations below, the hypothesis is only half correct â€” for even $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dad11d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T02:32:57.578920Z",
     "iopub.status.busy": "2025-02-17T02:32:57.578498Z",
     "iopub.status.idle": "2025-02-17T02:32:57.718353Z",
     "shell.execute_reply": "2025-02-17T02:32:57.716895Z"
    },
    "papermill": {
     "duration": 0.144853,
     "end_time": "2025-02-17T02:32:57.720848",
     "exception": false,
     "start_time": "2025-02-17T02:32:57.575995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 392\r\n",
      "-rw-r--r-- 1 nobody nogroup      0 Feb 16 10:51 custom.css\r\n",
      "-rw-r--r-- 1 nobody nogroup    659 Feb 16 10:51 __output__.json\r\n",
      "-rw-r--r-- 1 nobody nogroup 347399 Feb 16 10:51 __results__.html\r\n",
      "-rw-r--r-- 1 nobody nogroup  15695 Feb 16 10:51 __script__.ipynb\r\n",
      "-rw-r--r-- 1 nobody nogroup  14800 Feb 16 10:51 __script__.py\r\n",
      "-rw-r--r-- 1 nobody nogroup  14800 Feb 16 10:51 smallcg.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /kaggle/usr/lib/smallcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9defb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T02:32:57.726832Z",
     "iopub.status.busy": "2025-02-17T02:32:57.726455Z",
     "iopub.status.idle": "2025-02-17T02:33:09.250836Z",
     "shell.execute_reply": "2025-02-17T02:33:09.249143Z"
    },
    "papermill": {
     "duration": 11.529167,
     "end_time": "2025-02-17T02:33:09.252829",
     "exception": false,
     "start_time": "2025-02-17T02:32:57.723662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from smallcg import TensorPerms\n",
    "\n",
    "def get_LRX_moves(n):\n",
    "    L = np.array( list(np.arange(1,n)) + [0])\n",
    "    R = np.array( [n-1] + list(np.arange(n-1)) )\n",
    "    X = np.array( [1,0] + list(np.arange(2,n)) )\n",
    "    return np.array([L,R,X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1858196a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T02:33:09.258833Z",
     "iopub.status.busy": "2025-02-17T02:33:09.258289Z",
     "iopub.status.idle": "2025-02-17T02:33:09.268859Z",
     "shell.execute_reply": "2025-02-17T02:33:09.267699Z"
    },
    "papermill": {
     "duration": 0.015426,
     "end_time": "2025-02-17T02:33:09.270822",
     "exception": false,
     "start_time": "2025-02-17T02:33:09.255396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# n_generators = len( list_generators )\n",
    "# state_size = len(list_generators[0] )\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7555e93c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T02:33:09.276890Z",
     "iopub.status.busy": "2025-02-17T02:33:09.276427Z",
     "iopub.status.idle": "2025-02-17T02:33:09.286812Z",
     "shell.execute_reply": "2025-02-17T02:33:09.285690Z"
    },
    "papermill": {
     "duration": 0.01553,
     "end_time": "2025-02-17T02:33:09.288934",
     "exception": false,
     "start_time": "2025-02-17T02:33:09.273404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def beam_search_all(LRX, beam_width=1):\n",
    "    result = dict()\n",
    "    for i, state in enumerate(LRX.states):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        result[str(state.cpu().numpy())] = beam_search(LRX, state, beam_width)\n",
    "    return result\n",
    "\n",
    "def beam_search(LRX, state_start, beam_width=100, verbose=0):\n",
    "    n = LRX.n\n",
    "    n_steps_limit = 10*n**2\n",
    "    # Main storage data:\n",
    "    # Priority queue for the beam search; stores tuples of (cumulative cost, path, current state)\n",
    "    queue_beam = deque([(0, [], state_start )] )\n",
    "\n",
    "    # Set of all previously visited states \n",
    "    # We will ban visiting them again \n",
    "    set_seen_states = set( )\n",
    "    set_seen_states.add(str(LRX.states[0]))\n",
    "\n",
    "    counter_length = 0 # Path length counter \n",
    "    flag_path_found = False\n",
    "    path_found = []\n",
    "\n",
    "    while queue_beam: #  continue looping as long as queue is not empty. It should never be empty, unless graph is not conncected and path does not exists\n",
    "        counter_length += 1\n",
    "        #print('counter_length',counter_length)\n",
    "    \n",
    "        # Select top best states candidates - top-beam-width    \n",
    "        queue_beam = deque(sorted(list(queue_beam), key=lambda x: x[0])[:beam_width])\n",
    "\n",
    "        # Storage for newly generated states/costs/paths:\n",
    "        # They will be obtained by applying all moves to all states in beam \n",
    "        queue_beam_next = deque()\n",
    "\n",
    "        # That will be used just for monitoring - printing stat on obtained values \n",
    "        # Pay attention these are NOT cummulative costs \n",
    "        list_beam_q_values_for_monitoring = []\n",
    "\n",
    "        # Loop via current beam:\n",
    "        for cost, path, current_state in queue_beam:\n",
    "            #print('cost, path, current_state',cost, path, current_state)\n",
    "\n",
    "            # Loop via all possible moves \n",
    "            for i_action, action in enumerate(['L','R','X']):\n",
    "\n",
    "                #Check conditions for reasonable moves, disregard unreasoanble\n",
    "                # Condition proposed by S.Fironov - it is rather natural, is there theoretical proof ?\n",
    "                # if action == 'X' and current_state[0] < current_state[1]: # Heuristics \n",
    "                #    continue            \n",
    "                if action == 'L' and len(path) > 0 and path[-1] == 'R': # Non-backtracking\n",
    "                    continue\n",
    "                if action == 'R' and len(path) > 0 and path[-1] == 'L': # Non-backtracking\n",
    "                    continue\n",
    " \n",
    "                # Make a move (apply generator, i.e. go to neigbour node )\n",
    "                generator =  LRX.moves[i_action, :]\n",
    "                next_state = current_state[ generator ]\n",
    "\n",
    "                # Check destnation found: \n",
    "                if torch.all( next_state == LRX.states[0]) :\n",
    "                    flag_path_found = True\n",
    "                    path_found = path + [action]\n",
    "                    break \n",
    "\n",
    "                # Check the next_state is new or visited before \n",
    "                if str(next_state) not in set_seen_states:\n",
    "                    set_seen_states.add(str(next_state))\n",
    "\n",
    "                    # Compute heuristic distance to destination state\n",
    "                    # Here it is Hamming distance, but can be neural net predictor:\n",
    "                    # q_value = torch.sum( (next_state - state_destination ) !=0  ).item()\n",
    "                    q_value = state2dist[str(next_state.cpu().numpy())]\n",
    "                    list_beam_q_values_for_monitoring.append(q_value)\n",
    "\n",
    "                    # Cummulative cost: \n",
    "                    total_cost = q_value # + alpha_previous_cost_accumulation * cost  \n",
    "                    queue_beam_next.append((total_cost, path + [action], next_state))\n",
    "                \n",
    "                ###### End loop over actions/moves\n",
    "        \n",
    "            if flag_path_found: \n",
    "                break  # Path found. Stop process\n",
    "                \n",
    "        ###### End loop over beam\n",
    "    \n",
    "        if flag_path_found: break  # Path found. Stop process\n",
    "\n",
    "        if verbose >= 100:\n",
    "            if counter_length % 10 == 0:        \n",
    "                print('Step:',counter_length, 'Visited states:', len(set_seen_states), \n",
    "                  'Beam min:',  np.min( list_beam_q_values_for_monitoring),\n",
    "                  'median:',  np.median( list_beam_q_values_for_monitoring),\n",
    "                  'max:',  np.max( list_beam_q_values_for_monitoring) )\n",
    "            # print('new max len', len(path), len(queue), len(seen), \n",
    "            #       np.min(list_beam_q_values_for_monitoring), np.median(list_beam_q_values_for_monitoring),\n",
    "            #       np.mean(list_beam_q_values_for_monitoring), np.max(list_beam_q_values_for_monitoring) )\n",
    "        \n",
    "    \n",
    "        if counter_length > n_steps_limit:\n",
    "            flag_path_found = False\n",
    "            path_found = []\n",
    "            break\n",
    "\n",
    "\n",
    "        # Update the entire queu for new states/costs/paths:\n",
    "        queue_beam = queue_beam_next\n",
    "\n",
    "        ###### End loop iterations \n",
    "    return path_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d035c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T02:33:09.295644Z",
     "iopub.status.busy": "2025-02-17T02:33:09.295226Z",
     "iopub.status.idle": "2025-02-17T02:40:47.443163Z",
     "shell.execute_reply": "2025-02-17T02:40:47.442185Z"
    },
    "papermill": {
     "duration": 458.153751,
     "end_time": "2025-02-17T02:40:47.445566",
     "exception": false,
     "start_time": "2025-02-17T02:33:09.291815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1 took 0.47 s\n",
      "4 0 took 0.04 s\n",
      "5 26 took 0.40 s\n",
      "6 0 took 3.59 s\n",
      "7 1522 took 36.77 s\n",
      "8 0 took 416.87 s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "for n in range(3, 9):\n",
    "    begin = time()\n",
    "    LRX = TensorPerms(n, get_LRX_moves(n), verbose=False)\n",
    "    state2dist = dict()\n",
    "    for i, state in enumerate(LRX.states):\n",
    "        state2dist[str(state.cpu().numpy())] = int(LRX.distances[i].cpu().numpy())\n",
    "    state2path = beam_search_all(LRX)\n",
    "    equal_neighbors = 0\n",
    "    for i, perm in enumerate(LRX.states):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        np_perm = str(perm.cpu().numpy())\n",
    "        if len(state2path[np_perm]) != LRX.distances[i]:\n",
    "            print(i, len(state2path[np_perm]), LRX.distances[i])\n",
    "        if state2path[np_perm][0] == 'X':\n",
    "            # print(i, np_perm)\n",
    "            prev = 0\n",
    "            for k in range(1, n):\n",
    "                rolled = str(torch.roll(perm, k).cpu().numpy())\n",
    "                rolled_path = state2path[rolled]\n",
    "                if len(rolled_path) == prev: # and 2*k - 1 != n:\n",
    "                    equal_neighbors += 1\n",
    "                prev = len(rolled_path)\n",
    "    print(n, equal_neighbors, f\"took {time() - begin:.2f} s\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11024468,
     "sourceId": 92501,
     "sourceType": "competition"
    },
    {
     "sourceId": 222224147,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 475.767645,
   "end_time": "2025-02-17T02:40:50.526751",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-17T02:32:54.759106",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
