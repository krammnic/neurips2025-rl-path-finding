{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051ba099-2c84-460e-ab61-40b6c55dce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "def is_sorted(arr):\n",
    "    # Проверяем, отсортирован ли массив\n",
    "    return all(arr[i] <= arr[i + 1] for i in range(len(arr) - 1))\n",
    "\n",
    "class PermutationTransformer(nn.Module):\n",
    "    def __init__(self, n, d_model=64, nhead=4, num_layers=1, dim_feedforward=128):\n",
    "        super(PermutationTransformer, self).__init__()\n",
    "        \n",
    "        self.n = n\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Embedding слой для преобразования входных признаков\n",
    "        self.feature_embedding = nn.Linear(3, d_model)  # 3 признака: разница с позицией, разница справа, разница слева\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoder = nn.Parameter(torch.zeros(1, n, d_model))\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        # Выходной слой для 3 действий\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(n * d_model, dim_feedforward),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(dim_feedforward, dim_feedforward),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(dim_feedforward, dim_feedforward),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(dim_feedforward, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Преобразуем входные данные в матрицу признаков\n",
    "        features = torch.zeros(batch_size, self.n, 3, device=x.device)\n",
    "                \n",
    "        # Разница с позицией с учетом цикличности и знака\n",
    "        positions = torch.arange(self.n, device=x.device).expand(batch_size, -1)\n",
    "        raw_diff = x - positions\n",
    "        abs_diff = torch.abs(raw_diff) # обычное расстояние\n",
    "        cyclic_diff = torch.where(\n",
    "            abs_diff > self.n // 2,\n",
    "            torch.where(raw_diff > 0, -(self.n - abs_diff), self.n - abs_diff),\n",
    "            raw_diff\n",
    "        )\n",
    "        features[:, :, 0] = cyclic_diff\n",
    "       \n",
    "        # Разница с правым элементом\n",
    "        features[:, :, 1] = x - torch.roll(x, shifts=1, dims=1)\n",
    "        \n",
    "        # Разница с левым элементом\n",
    "        features[:, :, 2] = x - torch.roll(x, shifts=-1, dims=1)\n",
    "        \n",
    "        # Преобразуем признаки через embedding\n",
    "        embedded = self.feature_embedding(features)\n",
    "        \n",
    "        # Добавляем positional encoding\n",
    "        #embedded = embedded + self.pos_encoder\n",
    "        \n",
    "        # Пропускаем через transformer\n",
    "        transformer_output = self.transformer_encoder(embedded)\n",
    "        \n",
    "        # Flatten и выходной слой\n",
    "        flat = transformer_output.reshape(batch_size, -1)\n",
    "        q_values = self.output(flat)\n",
    "        \n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07352936-3431-4e2e-8357-20ea7c94e7a4",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def apply_action(perm, action):\n",
    "    perm = perm.copy()\n",
    "    if action == 0:  # swap 0 and 1\n",
    "        perm[0], perm[1] = perm[1], perm[0]\n",
    "    elif action == 1:  # rotate right\n",
    "        perm = np.roll(perm, 1)\n",
    "    else:  # rotate left\n",
    "        perm = np.roll(perm, -1)\n",
    "    return perm\n",
    "\n",
    "def tuple_perm(perm):\n",
    "    return tuple(perm)\n",
    "\n",
    "def generate_training_sample(n, k):\n",
    "    \"\"\"\n",
    "    Генерирует случайную перестановку, применяя не более k случайных ходов\n",
    "    к отсортированной последовательности\n",
    "    \"\"\"\n",
    "    perm = np.arange(n)\n",
    "    seen_states = {tuple_perm(perm)}\n",
    "    actual_moves = 0\n",
    "\n",
    "    perms = []\n",
    "    targets = [] \n",
    "    \n",
    "    for _ in range(k):\n",
    "        possible_actions = []\n",
    "        # Проверяем все возможные действия\n",
    "        for action in range(3):\n",
    "            if action == 0 and perm[0] > perm[1]:\n",
    "                continue\n",
    "            next_perm = apply_action(perm, action)\n",
    "            if tuple_perm(next_perm) not in seen_states:\n",
    "                possible_actions.append(action)\n",
    "        \n",
    "        # Если нет доступных ходов, прерываем\n",
    "        if not possible_actions:\n",
    "            break\n",
    "            \n",
    "        # Выбираем случайное действие\n",
    "        action = np.random.choice(possible_actions)\n",
    "        perm = apply_action(perm, action)\n",
    "        seen_states.add(tuple_perm(perm))\n",
    "        actual_moves += 1\n",
    "\n",
    "        perms.append(perm)\n",
    "        targets.append(actual_moves)\n",
    "\n",
    "    return perms, targets\n",
    "\n",
    "\n",
    "# Пример улучшенной версии с батчами:\n",
    "def generate_batch(n, max_moves, batch_size):\n",
    "    perms = []\n",
    "    targets = []\n",
    "    \n",
    "    for _ in range(batch_size):\n",
    "        k = np.random.randint(max_moves-1, max_moves + 1)\n",
    "        perm, moves = generate_training_sample(n, k)\n",
    "        perms.extend(perm)\n",
    "        targets.extend(moves)\n",
    "    \n",
    "    return torch.FloatTensor(np.array(perms)), torch.FloatTensor(targets)\n",
    "\n",
    "def train_model(model, n, max_moves, num_epochs, batch_size, learning_rate):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Генерируем батчи\n",
    "        for i in range(10):\n",
    "            batch_perms, batch_targets = generate_batch(n, max_moves, batch_size)\n",
    "            batch_perms = batch_perms.to(device)\n",
    "            batch_targets = batch_targets.to(device).unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_perms)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Выводим статистику эпохи\n",
    "        avg_loss = total_loss / num_batches\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Average Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "        # Проверяем модель на нескольких примерах\n",
    "        if epoch % 100 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for _ in range(1):\n",
    "                    #k = np.random.randint(1, max_moves + 1)\n",
    "                    k = max_moves\n",
    "                    test_perm, actual_moves = generate_training_sample(n, k)\n",
    "                    test_tensor = torch.FloatTensor(np.array(test_perm)).to(device)\n",
    "                    predicted_moves = model(test_tensor)\n",
    "                    for j in range(len(test_perm)):                    \n",
    "                        print(f\"Permutation: {test_perm[j]}\")\n",
    "                        print(f\"Actual moves: {actual_moves[j]}, Predicted: {predicted_moves[j].item():.2f}\")\n",
    "                print()\n",
    "\n",
    "n = 100  # размер перестановки\n",
    "max_moves = n*(n-1)//2  # максимальное число ходов\n",
    "num_epochs = 1000\n",
    "batch_size = 1\n",
    "learning_rate = 0.0003\n",
    "\n",
    "model = PermutationTransformer(n).cuda()\n",
    "train_model(model, n, max_moves, num_epochs, batch_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c0e1d2-9118-4923-a8b6-b2fdee2abf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new max len 100 3000 487511 4466.4130859375\n",
      "new max len 200 3000 955409 4271.8447265625\n",
      "new max len 300 3000 1387369 4165.74755859375\n",
      "new max len 400 3000 1824721 4076.861083984375\n",
      "new max len 500 3000 2292207 3815.860595703125\n",
      "new max len 600 3000 2721406 3716.184326171875\n",
      "new max len 700 3000 3133897 3666.57177734375\n",
      "new max len 800 3000 3552861 3584.751220703125\n",
      "new max len 900 3000 4028008 3283.881103515625\n",
      "new max len 1000 3000 4460160 3182.252685546875\n",
      "new max len 1100 3000 4886775 3054.591064453125\n",
      "new max len 1200 3000 5307003 2945.5712890625\n",
      "new max len 1300 3000 5710563 2885.424560546875\n",
      "new max len 1400 3000 6121108 2694.521240234375\n",
      "new max len 1500 3000 6536970 2695.101318359375\n",
      "new max len 1600 3000 6927630 2545.593505859375\n",
      "new max len 1700 3000 7312037 2276.962890625\n",
      "new max len 1800 3000 7696977 2181.089599609375\n",
      "new max len 1900 3000 8079028 2186.112548828125\n",
      "new max len 2000 3000 8456150 2097.048095703125\n",
      "new max len 2100 3000 8828585 1978.5848388671875\n",
      "new max len 2200 3000 9200479 1824.5245361328125\n",
      "new max len 2300 3000 9574079 1789.9930419921875\n",
      "new max len 2400 3000 9955708 1548.2845458984375\n",
      "new max len 2500 3000 10341254 1388.72021484375\n",
      "new max len 2600 3000 10722944 1009.6006469726562\n",
      "new max len 2700 3000 11105036 949.9300537109375\n",
      "new max len 2800 3000 11487713 918.6085815429688\n",
      "new max len 2900 3000 11866806 925.7982177734375\n",
      "new max len 3000 3000 12248168 775.2125244140625\n",
      "new max len 3100 3000 12629801 717.93603515625\n",
      "new max len 3200 3000 13001354 703.77001953125\n",
      "new max len 3300 3000 13370968 672.4862670898438\n",
      "new max len 3400 3000 13739169 676.5170288085938\n",
      "new max len 3500 3000 14108133 660.1648559570312\n",
      "new max len 3600 3000 14476974 681.3695068359375\n",
      "new max len 3700 3000 14846979 666.458251953125\n",
      "new max len 3800 3000 15216931 657.9435424804688\n",
      "new max len 3900 3000 15587203 639.3025512695312\n",
      "new max len 4000 3000 15956801 641.8955078125\n",
      "new max len 4100 3000 16326361 641.8455200195312\n",
      "new max len 4200 3000 16696662 598.3094482421875\n",
      "new max len 4300 3000 17066466 607.0653686523438\n",
      "new max len 4400 3000 17435352 600.306884765625\n",
      "new max len 4500 3000 17802563 589.27392578125\n",
      "new max len 4600 3000 18172438 532.068359375\n",
      "new max len 4700 3000 18550696 491.36431884765625\n",
      "new max len 4800 3000 18916276 438.6588134765625\n",
      "new max len 4900 3000 19277164 341.0089111328125\n",
      "new max len 5000 3000 19640723 252.02394104003906\n",
      "new max len 5100 3000 20002548 222.99449157714844\n",
      "new max len 5200 3000 20362967 200.49188232421875\n",
      "new max len 5300 3000 20722938 208.51219177246094\n",
      "new max len 5400 3000 21082812 217.89434814453125\n",
      "new max len 5500 3000 21444350 184.4330596923828\n",
      "new max len 5600 3000 21805167 187.95042419433594\n",
      "new max len 5700 3000 22166629 143.2096405029297\n",
      "new max len 5800 3000 22526322 155.01806640625\n",
      "new max len 5900 3000 22884483 121.23743438720703\n",
      "new max len 6000 3000 23240348 122.61942291259766\n",
      "new max len 6100 3000 23596045 97.2660140991211\n",
      "new max len 6200 3000 23951699 127.80145263671875\n",
      "new max len 6300 3000 24307953 90.83348846435547\n",
      "new max len 6400 3000 24664647 86.49518585205078\n",
      "new max len 6500 3000 25020113 100.2411117553711\n",
      "new max len 6600 3000 25376342 85.46543884277344\n",
      "new max len 6700 3000 25734207 77.52814483642578\n",
      "new max len 6800 3000 26089583 96.10334014892578\n",
      "new max len 6900 3000 26447172 77.04505157470703\n",
      "new max len 7000 3000 26802233 48.926239013671875\n",
      "new max len 7100 3000 27155873 39.51274108886719\n",
      "new max len 7200 3000 27502805 29.46382713317871\n",
      "new max len 7300 3000 27839656 14.182389259338379\n",
      "new max len 7400 3000 28187988 18.78972816467285\n",
      "new max len 7500 3000 28534156 14.699098587036133\n",
      "new max len 7600 3000 28884889 11.127971649169922\n",
      "new max len 7700 3000 29240958 18.227569580078125\n",
      "new max len 7800 3000 29597719 10.246994018554688\n",
      "new max len 7900 3000 29952344 9.984015464782715\n",
      "new max len 8000 3000 30302521 18.703275680541992\n",
      "new max len 8100 3000 30650695 10.114788055419922\n",
      "new max len 8200 3000 30997452 6.820722579956055\n",
      "new max len 8300 3000 31338833 6.489954471588135\n",
      "new max len 8400 3000 31675673 4.538559913635254\n",
      "new max len 8500 3000 32006749 3.2619659900665283\n",
      "Кратчайший путь: 8524\n",
      "['X', 'L', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'X', 'L', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'X', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'X', 'L', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'X', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'X', 'R', 'X', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'X', 'R', 'R', 'X', 'R', 'R', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'X', 'L', 'L', 'X', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'X', 'L', 'L', 'X', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'L', 'X', 'R', 'X', 'R', 'R', 'X', 'L', 'X', 'R', 'R', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'R', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'L', 'X', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'R', 'X', 'L', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'X', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L']\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "def beam_search_sorting(permutation, beam_width=5):\n",
    "    n = len(permutation)\n",
    "    target = list(range(0, n))\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def average_neighbor_difference(perm):\n",
    "        total_diff = 0\n",
    "        \n",
    "        # Считаем разницы между соседними элементами\n",
    "        for i in range(n-1):\n",
    "            total_diff += abs(perm[i] - perm[i+1])\n",
    "        \n",
    "        # Добавляем разницу между последним и первым элементом\n",
    "        total_diff += abs(perm[-1] - perm[0])\n",
    "        \n",
    "        return total_diff / n\n",
    "\n",
    "    def count_monotonic_sections(perm):\n",
    "        # Создаем расширенную перестановку для учета цикличности\n",
    "        extended_perm = perm + perm[0:1]\n",
    "        \n",
    "        sections = 0\n",
    "        increasing = None\n",
    "        \n",
    "        for i in range(n):\n",
    "            if increasing is None:  # Первое сравнение\n",
    "                increasing = extended_perm[i] < extended_perm[i + 1]\n",
    "            elif increasing and extended_perm[i] > extended_perm[i + 1]:  # Смена возрастания на убывание\n",
    "                sections += 1\n",
    "                increasing = False\n",
    "            elif not increasing and extended_perm[i] < extended_perm[i + 1]:  # Смена убывания на возрастание\n",
    "                sections += 1\n",
    "                increasing = True\n",
    "                \n",
    "        return sections / n\n",
    "    \n",
    "    def apply_actions(state):\n",
    "        # Generate new states based on the allowed actions\n",
    "        states = []\n",
    "        # 1. Cyclic shift right\n",
    "        new_state = state[-1:] + state[:-1]\n",
    "        states.append((new_state, \"R\"))\n",
    "        \n",
    "        # 2. Cyclic shift left\n",
    "        new_state = state[1:] + state[:1]\n",
    "        states.append((new_state, \"L\"))\n",
    "        \n",
    "        # 3. Swap first two elements\n",
    "        if len(state) > 1:\n",
    "            new_state = state[:]\n",
    "            new_state[0], new_state[1] = new_state[1], new_state[0]\n",
    "            states.append((new_state, \"X\"))\n",
    "        \n",
    "        return states\n",
    "\n",
    "    def apply_action(state, action):\n",
    "        # 1. Cyclic shift right\n",
    "        if action == 'R':\n",
    "            new_state = state[-1:] + state[:-1]\n",
    "            return new_state\n",
    "        elif action == 'L':        \n",
    "            # 2. Cyclic shift left\n",
    "            new_state = state[1:] + state[:1]\n",
    "            return new_state\n",
    "            \n",
    "        new_state = state[:]\n",
    "        new_state[0], new_state[1] = new_state[1], new_state[0]\n",
    "        return new_state\n",
    "            \n",
    "    \n",
    "    # Priority queue for the beam search; stores tuples of (cumulative cost, path, current state)\n",
    "    queue = deque([(0, [], permutation)])\n",
    "    seen = set()\n",
    "\n",
    "    max_actions = 0\n",
    "    q_values = []\n",
    "    \n",
    "    while queue:\n",
    "        # Limit the size of the queue as per beam width\n",
    "        queue = deque(sorted(list(queue), key=lambda x: x[0])[:beam_width])\n",
    "        next_queue = deque()\n",
    "        \n",
    "        for cost, path, current in queue:\n",
    "            if len(path) > max_actions:\n",
    "                max_actions = len(path)\n",
    "                if max_actions % 100 == 0:\n",
    "                    print('new max len', len(path), len(queue), len(seen), np.min(q_values))\n",
    "                q_values = []\n",
    "            if len(path) > 40000:\n",
    "                #print('long path', queue)\n",
    "                return None\n",
    "            if current == target:\n",
    "                return path  # Return the path to sorted order\n",
    "\n",
    "\n",
    "            for action in ['L','R','X']:\n",
    "                if action == 'L' and len(path) > 0 and path[-1] == 'R':\n",
    "                    continue\n",
    "                if action == 'R' and len(path) > 0 and path[-1] == 'L':\n",
    "                    continue\n",
    "                if action == 'X' and current[0] < current[1]:\n",
    "                    continue\n",
    "\n",
    "                next_state = apply_action(current, action)\n",
    "\n",
    "                if tuple(next_state) not in seen:\n",
    "                    seen.add(tuple(next_state))\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        t_state = torch.FloatTensor(next_state).unsqueeze(0).to(device)\n",
    "                        q_value = model(t_state).squeeze().item()\n",
    "                        q_values.append(q_value)\n",
    "                    \n",
    "                    total_cost = cost + 1 + q_value\n",
    "                    next_queue.append((total_cost, path + [action], next_state))\n",
    "        \n",
    "        queue = next_queue\n",
    "\n",
    "    return None  # Return None if no solution is found\n",
    "\n",
    "# Пример использования\n",
    "n = 100\n",
    "p = np.arange(n)\n",
    "p[0], p[1] = p[1], p[0]\n",
    "i = 2\n",
    "while i < n-i+1:\n",
    "    p[i], p[n-i+1] = p[n-i+1], p[i]\n",
    "    i += 1\n",
    "permutation = p.tolist()\n",
    "\n",
    "k = 3000  # Ширина \"луча\"\n",
    "model.eval();\n",
    "path = beam_search_sorting(permutation, beam_width=k)\n",
    "print(\"Кратчайший путь:\", len(path))\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0469e944-d705-435d-9629-78ee5d998c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 99, 98, 97, 96, 95, 94, 93, 92, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 64, 63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "def perform_action(state, action):\n",
    "    temp_arr = state.copy()\n",
    "    if action == 'L':\n",
    "        temp_arr = temp_arr[1:] + [temp_arr[0]]\n",
    "    elif action == 'R':\n",
    "        temp_arr = [temp_arr[-1]] + temp_arr[:-1]\n",
    "    elif action == 'X':\n",
    "        temp_arr[0], temp_arr[1] = temp_arr[1], temp_arr[0]\n",
    "\n",
    "    return temp_arr\n",
    "\n",
    "p = permutation.copy()\n",
    "s = p.copy()\n",
    "for action in path:\n",
    "    s = perform_action(s, action)\n",
    "print(p)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3197e17-3a6e-4a73-b11d-063e98c0257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_100.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09bd61b-c8dd-42ad-9f86-8d7c05afad59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2450"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in path if x=='X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f32ee-3c53-4ad3-b3c3-fdbed495e136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
